2025-06-08 16:41:04,836 - INFO - 🚀 Loading model: meta-llama/Llama-3.2-3B
2025-06-08 16:41:05,146 - INFO - ✅ HF authentication successful
2025-06-08 16:41:08,038 - INFO - Tokenizer loaded - vocab_size: 128256
2025-06-08 16:41:08,777 - INFO - ✅ Fixed ALL_PARALLEL_STYLES
2025-06-08 16:41:26,516 - ERROR - Model loading failed: LlamaForCausalLM.__init__() got an unexpected keyword argument 'use_cache'
2025-06-08 16:41:27,018 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 16:41:28,735 - INFO - ✅ Model loaded with alternative method (float32)
2025-06-08 16:41:28,737 - INFO - ✅ Model loaded - 3,212,749,824 parameters
2025-06-08 16:41:28,737 - INFO -    GPU: NVIDIA A100-SXM4-80GB - 79.3GB VRAM
2025-06-08 16:41:28,738 - INFO - 📁 Loading SFT dataset: /root/codexglue_train.json
2025-06-08 16:41:29,273 - INFO - ✅ Loaded 100000 samples
2025-06-08 16:41:29,297 - INFO - 
📊 Train/Val Split:
2025-06-08 16:41:29,298 - INFO - 🚂 TRAIN SET: 90000 samples
2025-06-08 16:41:29,298 - INFO - 🧪 VALIDATION SET: 10000 samples
2025-06-08 16:41:29,298 - INFO - 
🔍 Validation Set Examples (first 3):
2025-06-08 16:41:29,298 - INFO -   [0] ID: 3813
2025-06-08 16:41:29,298 - INFO -        NL: get the factory that is used by default for the #create method is invoked . concode_field_sep Object...
2025-06-08 16:41:29,298 - INFO -   [1] ID: 99183
2025-06-08 16:41:29,298 - INFO -        NL: render exceptions . sets the response status accordingly to note bad requests . concode_field_sep Pl...
2025-06-08 16:41:29,298 - INFO -   [2] ID: 80737
2025-06-08 16:41:29,298 - INFO -        NL: retrieves diagnostics information preserved in the history file concode_field_sep Iterable<String> N...
2025-06-08 16:41:29,298 - INFO - 🎯 Creating SFT Dataset:
2025-06-08 16:41:29,298 - INFO -    Total samples: 90000
2025-06-08 16:41:29,298 - INFO - 🔥 PRE-TOKENIZING ALL SAMPLES...
2025-06-08 16:42:06,062 - INFO - ✅ Tokenization complete: 90000 entries
2025-06-08 16:42:06,063 - INFO - 🎯 Creating SFT Dataset:
2025-06-08 16:42:06,063 - INFO -    Total samples: 10000
2025-06-08 16:42:06,063 - INFO - 🔥 PRE-TOKENIZING ALL SAMPLES...
2025-06-08 16:42:10,969 - INFO - ✅ Tokenization complete: 10000 entries
2025-06-08 16:42:10,973 - INFO - 🎯 Optimizer setup:
2025-06-08 16:42:10,973 - INFO -    Steps per epoch: 1875
2025-06-08 16:42:10,973 - INFO -    Total steps: 5625
2025-06-08 16:42:10,973 - INFO -    Warmup steps: 168
2025-06-08 16:42:10,973 - INFO -    Eval frequency: every 375 steps (5x per epoch)
2025-06-08 16:42:10,973 - INFO - 🚀 Starting SFT-only training...
2025-06-08 16:42:10,973 - INFO -    📊 Dataset: codexglue_train.json
2025-06-08 16:42:10,973 - INFO -    🎯 Each sample appears exactly once per epoch
2025-06-08 16:42:10,973 - INFO -    🔧 Early stopping (patience=3)
2025-06-08 16:42:10,973 - INFO -    📈 5 evaluations per epoch
2025-06-08 16:42:10,973 - INFO -    💾 Best model saved based on validation loss
2025-06-08 16:42:10,973 - INFO - 
🎯 EPOCH 1/3
2025-06-08 16:43:03,968 - INFO - 🚀 Step   10 | Loss: 2.5574 | LR: 1.19e-06
2025-06-08 16:43:03,969 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:43:55,723 - INFO - 🚀 Step   20 | Loss: 1.4253 | LR: 2.38e-06
2025-06-08 16:43:55,724 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:44:50,599 - INFO - 🚀 Step   30 | Loss: 1.1913 | LR: 3.57e-06
2025-06-08 16:44:50,600 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:45:42,460 - INFO - 🚀 Step   40 | Loss: 1.1153 | LR: 4.76e-06
2025-06-08 16:45:42,460 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:46:36,313 - INFO - 🚀 Step   50 | Loss: 1.0848 | LR: 5.95e-06
2025-06-08 16:46:36,314 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:47:29,454 - INFO - 🚀 Step   60 | Loss: 1.0939 | LR: 7.14e-06
2025-06-08 16:47:29,454 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:48:19,620 - INFO - 🚀 Step   70 | Loss: 0.9870 | LR: 8.33e-06
2025-06-08 16:48:19,621 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:49:14,682 - INFO - 🚀 Step   80 | Loss: 1.0388 | LR: 9.52e-06
2025-06-08 16:49:14,683 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:50:08,565 - INFO - 🚀 Step   90 | Loss: 1.0479 | LR: 1.07e-05
2025-06-08 16:50:08,565 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:50:59,489 - INFO - 🚀 Step  100 | Loss: 1.0387 | LR: 1.19e-05
2025-06-08 16:50:59,489 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:51:50,960 - INFO - 🚀 Step  110 | Loss: 1.0241 | LR: 1.31e-05
2025-06-08 16:51:50,961 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:52:44,303 - INFO - 🚀 Step  120 | Loss: 1.0311 | LR: 1.43e-05
2025-06-08 16:52:44,304 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:53:37,225 - INFO - 🚀 Step  130 | Loss: 1.0136 | LR: 1.55e-05
2025-06-08 16:53:37,225 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:54:30,255 - INFO - 🚀 Step  140 | Loss: 0.9883 | LR: 1.67e-05
2025-06-08 16:54:30,256 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:55:21,156 - INFO - 🚀 Step  150 | Loss: 0.9911 | LR: 1.79e-05
2025-06-08 16:55:21,156 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:56:15,838 - INFO - 🚀 Step  160 | Loss: 1.0074 | LR: 1.90e-05
2025-06-08 16:56:15,839 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:57:10,671 - INFO - 🚀 Step  170 | Loss: 0.9809 | LR: 2.00e-05
2025-06-08 16:57:10,671 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:58:00,343 - INFO - 🚀 Step  180 | Loss: 1.0416 | LR: 2.00e-05
2025-06-08 16:58:00,344 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:58:53,196 - INFO - 🚀 Step  190 | Loss: 1.0114 | LR: 2.00e-05
2025-06-08 16:58:53,196 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 16:59:45,806 - INFO - 🚀 Step  200 | Loss: 0.9815 | LR: 2.00e-05
2025-06-08 16:59:45,807 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:00:36,820 - INFO - 🚀 Step  210 | Loss: 0.9929 | LR: 2.00e-05
2025-06-08 17:00:36,820 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:01:31,575 - INFO - 🚀 Step  220 | Loss: 0.9929 | LR: 2.00e-05
2025-06-08 17:01:31,575 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:02:21,244 - INFO - 🚀 Step  230 | Loss: 0.9981 | LR: 2.00e-05
2025-06-08 17:02:21,244 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:03:17,078 - INFO - 🚀 Step  240 | Loss: 0.9670 | LR: 2.00e-05
2025-06-08 17:03:17,078 - INFO -    GPU: 35.9GB/79.3GB (45.4%)
2025-06-08 17:04:08,591 - INFO - 🚀 Step  250 | Loss: 0.9823 | LR: 2.00e-05
2025-06-08 17:04:08,591 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:05:02,255 - INFO - 🚀 Step  260 | Loss: 0.9747 | LR: 2.00e-05
2025-06-08 17:05:02,255 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:05:52,419 - INFO - 🚀 Step  270 | Loss: 0.9078 | LR: 2.00e-05
2025-06-08 17:05:52,419 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:06:45,599 - INFO - 🚀 Step  280 | Loss: 0.9272 | LR: 2.00e-05
2025-06-08 17:06:45,600 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:07:35,020 - INFO - 🚀 Step  290 | Loss: 0.9261 | LR: 2.00e-05
2025-06-08 17:07:35,020 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:08:30,015 - INFO - 🚀 Step  300 | Loss: 0.9370 | LR: 2.00e-05
2025-06-08 17:08:30,015 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:09:23,740 - INFO - 🚀 Step  310 | Loss: 0.8889 | LR: 2.00e-05
2025-06-08 17:09:23,741 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:10:17,122 - INFO - 🚀 Step  320 | Loss: 0.9534 | LR: 2.00e-05
2025-06-08 17:10:17,122 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:11:10,528 - INFO - 🚀 Step  330 | Loss: 0.9231 | LR: 2.00e-05
2025-06-08 17:11:10,529 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:12:02,887 - INFO - 🚀 Step  340 | Loss: 0.9182 | LR: 2.00e-05
2025-06-08 17:12:02,888 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:12:56,972 - INFO - 🚀 Step  350 | Loss: 0.8997 | LR: 1.99e-05
2025-06-08 17:12:56,973 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:13:47,470 - INFO - 🚀 Step  360 | Loss: 0.9646 | LR: 1.99e-05
2025-06-08 17:13:47,471 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:14:43,277 - INFO - 🚀 Step  370 | Loss: 0.8951 | LR: 1.99e-05
2025-06-08 17:14:43,277 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:19:44,154 - INFO - 
============================================================
2025-06-08 17:19:44,155 - INFO - 📊 VALIDATION 1/5 - Epoch 1, Step 375
2025-06-08 17:19:44,155 - INFO - ============================================================
2025-06-08 17:19:44,155 - INFO -   • Average Loss: 0.9319
2025-06-08 17:19:44,155 - INFO -   • Sample Average: 0.9108 (10000 samples)
2025-06-08 17:19:55,472 - INFO - ✅ New best model saved in memory
2025-06-08 17:19:55,473 - INFO -   • Early Stop: 0/3
2025-06-08 17:19:55,473 - INFO -   • Best Loss: 0.9319 (epoch 0, step 375)
2025-06-08 17:19:55,473 - INFO - ============================================================

2025-06-08 17:19:55,473 - INFO - 🏆 New best model! Saving...
2025-06-08 17:19:55,473 - INFO - 💾 Attempting to save model to: /root/llama3.2-3b-sft-training/best/model
2025-06-08 17:19:55,474 - INFO -    Trying standard safe save...
2025-06-08 17:19:55,595 - WARNING -    Standard safe save failed: cannot import name 'DTensor' from 'torch.distributed.tensor' (/usr/local/lib/python3.11/dist-packages/torch/distributed/tensor/__init__.py)
2025-06-08 17:19:55,595 - INFO -    Trying without safe serialization...
2025-06-08 17:19:55,616 - WARNING -    Non-safe save failed: name 'DTensor' is not defined
2025-06-08 17:19:55,616 - INFO -    Trying manual state dict save...
2025-06-08 17:20:12,706 - INFO - ✅ Manual save successful!
2025-06-08 17:21:00,802 - INFO - 💾 Checkpoint saved: /root/llama3.2-3b-sft-training/checkpoints/checkpoint-best.pt
2025-06-08 17:21:27,538 - INFO - 🚀 Step  380 | Loss: 0.9179 | LR: 1.99e-05
2025-06-08 17:21:27,538 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:22:19,820 - INFO - 🚀 Step  390 | Loss: 0.9167 | LR: 1.99e-05
2025-06-08 17:22:19,821 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:23:08,900 - INFO - 🚀 Step  400 | Loss: 0.9553 | LR: 1.99e-05
2025-06-08 17:23:08,901 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:24:03,153 - INFO - 🚀 Step  410 | Loss: 0.9249 | LR: 1.99e-05
2025-06-08 17:24:03,153 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:24:54,356 - INFO - 🚀 Step  420 | Loss: 0.8689 | LR: 1.99e-05
2025-06-08 17:24:54,356 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:25:43,745 - INFO - 🚀 Step  430 | Loss: 0.8608 | LR: 1.99e-05
2025-06-08 17:25:43,745 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:26:37,634 - INFO - 🚀 Step  440 | Loss: 0.8986 | LR: 1.99e-05
2025-06-08 17:26:37,634 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:27:28,667 - INFO - 🚀 Step  450 | Loss: 0.8726 | LR: 1.99e-05
2025-06-08 17:27:28,667 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:28:21,377 - INFO - 🚀 Step  460 | Loss: 0.8811 | LR: 1.99e-05
2025-06-08 17:28:21,377 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:29:12,583 - INFO - 🚀 Step  470 | Loss: 0.9011 | LR: 1.98e-05
2025-06-08 17:29:12,583 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:30:02,087 - INFO - 🚀 Step  480 | Loss: 0.8843 | LR: 1.98e-05
2025-06-08 17:30:02,088 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:30:52,184 - INFO - 🚀 Step  490 | Loss: 0.8633 | LR: 1.98e-05
2025-06-08 17:30:52,184 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:31:44,616 - INFO - 🚀 Step  500 | Loss: 0.9013 | LR: 1.98e-05
2025-06-08 17:31:44,617 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:32:37,438 - INFO - 🚀 Step  510 | Loss: 0.8883 | LR: 1.98e-05
2025-06-08 17:32:37,438 - INFO -    GPU: 35.9GB/79.3GB (45.4%)
2025-06-08 17:33:30,185 - INFO - 🚀 Step  520 | Loss: 0.8614 | LR: 1.98e-05
2025-06-08 17:33:30,185 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:34:23,943 - INFO - 🚀 Step  530 | Loss: 0.8691 | LR: 1.98e-05
2025-06-08 17:34:23,943 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:35:16,121 - INFO - 🚀 Step  540 | Loss: 0.8833 | LR: 1.98e-05
2025-06-08 17:35:16,122 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:36:09,737 - INFO - 🚀 Step  550 | Loss: 0.8944 | LR: 1.98e-05
2025-06-08 17:36:09,738 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:37:01,200 - INFO - 🚀 Step  560 | Loss: 0.8763 | LR: 1.97e-05
2025-06-08 17:37:01,200 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:37:53,458 - INFO - 🚀 Step  570 | Loss: 0.8505 | LR: 1.97e-05
2025-06-08 17:37:53,459 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:38:45,489 - INFO - 🚀 Step  580 | Loss: 0.8557 | LR: 1.97e-05
2025-06-08 17:38:45,489 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:39:39,088 - INFO - 🚀 Step  590 | Loss: 0.8667 | LR: 1.97e-05
2025-06-08 17:39:39,088 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:40:33,963 - INFO - 🚀 Step  600 | Loss: 0.8770 | LR: 1.97e-05
2025-06-08 17:40:33,963 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:41:24,929 - INFO - 🚀 Step  610 | Loss: 0.8762 | LR: 1.97e-05
2025-06-08 17:41:24,929 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:42:19,442 - INFO - 🚀 Step  620 | Loss: 0.8906 | LR: 1.97e-05
2025-06-08 17:42:19,442 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:43:09,271 - INFO - 🚀 Step  630 | Loss: 0.8217 | LR: 1.96e-05
2025-06-08 17:43:09,271 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:44:04,878 - INFO - 🚀 Step  640 | Loss: 0.8477 | LR: 1.96e-05
2025-06-08 17:44:04,878 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:44:55,657 - INFO - 🚀 Step  650 | Loss: 0.8127 | LR: 1.96e-05
2025-06-08 17:44:55,657 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:45:47,048 - INFO - 🚀 Step  660 | Loss: 0.8253 | LR: 1.96e-05
2025-06-08 17:45:47,049 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:46:42,658 - INFO - 🚀 Step  670 | Loss: 0.8534 | LR: 1.96e-05
2025-06-08 17:46:42,659 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:47:36,700 - INFO - 🚀 Step  680 | Loss: 0.8505 | LR: 1.96e-05
2025-06-08 17:47:36,701 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:48:28,384 - INFO - 🚀 Step  690 | Loss: 0.8450 | LR: 1.96e-05
2025-06-08 17:48:28,384 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:49:22,305 - INFO - 🚀 Step  700 | Loss: 0.8711 | LR: 1.95e-05
2025-06-08 17:49:22,306 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:50:11,650 - INFO - 🚀 Step  710 | Loss: 0.8342 | LR: 1.95e-05
2025-06-08 17:50:11,651 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:51:00,828 - INFO - 🚀 Step  720 | Loss: 0.8236 | LR: 1.95e-05
2025-06-08 17:51:00,828 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:51:51,829 - INFO - 🚀 Step  730 | Loss: 0.8795 | LR: 1.95e-05
2025-06-08 17:51:51,830 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:52:46,116 - INFO - 🚀 Step  740 | Loss: 0.8242 | LR: 1.95e-05
2025-06-08 17:52:46,117 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 17:58:16,296 - INFO - 
============================================================
2025-06-08 17:58:16,296 - INFO - 📊 VALIDATION 2/5 - Epoch 1, Step 750
2025-06-08 17:58:16,296 - INFO - ============================================================
2025-06-08 17:58:16,296 - INFO -   • Average Loss: 0.8375
2025-06-08 17:58:16,297 - INFO -   • Sample Average: 0.8228 (10000 samples)
2025-06-08 17:58:32,379 - INFO - ✅ New best model saved in memory
2025-06-08 17:58:32,379 - INFO -   • Early Stop: 0/3
2025-06-08 17:58:32,380 - INFO -   • Best Loss: 0.8375 (epoch 0, step 750)
2025-06-08 17:58:32,380 - INFO - ============================================================

2025-06-08 17:58:32,380 - INFO - 🏆 New best model! Saving...
2025-06-08 17:58:32,381 - INFO - 💾 Attempting to save model to: /root/llama3.2-3b-sft-training/best/model
2025-06-08 17:58:32,381 - INFO -    Trying standard safe save...
2025-06-08 17:58:32,385 - WARNING -    Standard safe save failed: cannot import name 'DTensor' from 'torch.distributed.tensor' (/usr/local/lib/python3.11/dist-packages/torch/distributed/tensor/__init__.py)
2025-06-08 17:58:32,385 - INFO -    Trying without safe serialization...
2025-06-08 17:58:32,405 - WARNING -    Non-safe save failed: name 'DTensor' is not defined
2025-06-08 17:58:32,406 - INFO -    Trying manual state dict save...
2025-06-08 17:58:45,359 - INFO - ✅ Manual save successful!
2025-06-08 17:59:23,529 - INFO - 💾 Checkpoint saved: /root/llama3.2-3b-sft-training/checkpoints/checkpoint-best.pt
2025-06-08 17:59:23,531 - INFO - 🚀 Step  750 | Loss: 0.8691 | LR: 1.94e-05
2025-06-08 17:59:23,531 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:00:16,294 - INFO - 🚀 Step  760 | Loss: 0.8684 | LR: 1.94e-05
2025-06-08 18:00:16,295 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:01:10,414 - INFO - 🚀 Step  770 | Loss: 0.8503 | LR: 1.94e-05
2025-06-08 18:01:10,415 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:02:01,118 - INFO - 🚀 Step  780 | Loss: 0.8203 | LR: 1.94e-05
2025-06-08 18:02:01,119 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:02:52,085 - INFO - 🚀 Step  790 | Loss: 0.8271 | LR: 1.94e-05
2025-06-08 18:02:52,085 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:03:47,259 - INFO - 🚀 Step  800 | Loss: 0.8169 | LR: 1.93e-05
2025-06-08 18:03:47,259 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:04:37,113 - INFO - 🚀 Step  810 | Loss: 0.8097 | LR: 1.93e-05
2025-06-08 18:04:37,113 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:05:31,772 - INFO - 🚀 Step  820 | Loss: 0.7860 | LR: 1.93e-05
2025-06-08 18:05:31,772 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:06:22,998 - INFO - 🚀 Step  830 | Loss: 0.8446 | LR: 1.93e-05
2025-06-08 18:06:22,998 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:07:14,056 - INFO - 🚀 Step  840 | Loss: 0.7986 | LR: 1.93e-05
2025-06-08 18:07:14,057 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:08:07,027 - INFO - 🚀 Step  850 | Loss: 0.8218 | LR: 1.92e-05
2025-06-08 18:08:07,027 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:08:57,759 - INFO - 🚀 Step  860 | Loss: 0.8471 | LR: 1.92e-05
2025-06-08 18:08:57,759 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:09:52,774 - INFO - 🚀 Step  870 | Loss: 0.8391 | LR: 1.92e-05
2025-06-08 18:09:52,774 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:10:47,968 - INFO - 🚀 Step  880 | Loss: 0.8224 | LR: 1.92e-05
2025-06-08 18:10:47,968 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:11:39,169 - INFO - 🚀 Step  890 | Loss: 0.8809 | LR: 1.91e-05
2025-06-08 18:11:39,170 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:12:30,715 - INFO - 🚀 Step  900 | Loss: 0.8759 | LR: 1.91e-05
2025-06-08 18:12:30,715 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:13:23,864 - INFO - 🚀 Step  910 | Loss: 0.7767 | LR: 1.91e-05
2025-06-08 18:13:23,864 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:14:16,298 - INFO - 🚀 Step  920 | Loss: 0.8316 | LR: 1.91e-05
2025-06-08 18:14:16,298 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:15:11,953 - INFO - 🚀 Step  930 | Loss: 0.7831 | LR: 1.91e-05
2025-06-08 18:15:11,953 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:16:05,521 - INFO - 🚀 Step  940 | Loss: 0.8003 | LR: 1.90e-05
2025-06-08 18:16:05,521 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:16:55,069 - INFO - 🚀 Step  950 | Loss: 0.7924 | LR: 1.90e-05
2025-06-08 18:16:55,069 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:17:44,585 - INFO - 🚀 Step  960 | Loss: 0.7728 | LR: 1.90e-05
2025-06-08 18:17:44,586 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:18:36,356 - INFO - 🚀 Step  970 | Loss: 0.7610 | LR: 1.90e-05
2025-06-08 18:18:36,357 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:19:28,893 - INFO - 🚀 Step  980 | Loss: 0.7951 | LR: 1.89e-05
2025-06-08 18:19:28,893 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:20:21,568 - INFO - 🚀 Step  990 | Loss: 0.7646 | LR: 1.89e-05
2025-06-08 18:20:21,569 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:21:13,753 - INFO - 🚀 Step 1000 | Loss: 0.7971 | LR: 1.89e-05
2025-06-08 18:21:13,753 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:22:04,953 - INFO - 🚀 Step 1010 | Loss: 0.7418 | LR: 1.88e-05
2025-06-08 18:22:04,953 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:22:55,153 - INFO - 🚀 Step 1020 | Loss: 0.7889 | LR: 1.88e-05
2025-06-08 18:22:55,153 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:23:45,571 - INFO - 🚀 Step 1030 | Loss: 0.7831 | LR: 1.88e-05
2025-06-08 18:23:45,572 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:24:37,832 - INFO - 🚀 Step 1040 | Loss: 0.7804 | LR: 1.88e-05
2025-06-08 18:24:37,832 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:25:28,903 - INFO - 🚀 Step 1050 | Loss: 0.7876 | LR: 1.87e-05
2025-06-08 18:25:28,903 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:26:22,197 - INFO - 🚀 Step 1060 | Loss: 0.7989 | LR: 1.87e-05
2025-06-08 18:26:22,197 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:27:12,042 - INFO - 🚀 Step 1070 | Loss: 0.7317 | LR: 1.87e-05
2025-06-08 18:27:12,043 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:28:05,682 - INFO - 🚀 Step 1080 | Loss: 0.8092 | LR: 1.87e-05
2025-06-08 18:28:05,682 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:28:58,120 - INFO - 🚀 Step 1090 | Loss: 0.7718 | LR: 1.86e-05
2025-06-08 18:28:58,120 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:29:53,992 - INFO - 🚀 Step 1100 | Loss: 0.7959 | LR: 1.86e-05
2025-06-08 18:29:53,992 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:30:47,340 - INFO - 🚀 Step 1110 | Loss: 0.7907 | LR: 1.86e-05
2025-06-08 18:30:47,340 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:31:39,488 - INFO - 🚀 Step 1120 | Loss: 0.7566 | LR: 1.85e-05
2025-06-08 18:31:39,488 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:36:42,366 - INFO - 
============================================================
2025-06-08 18:36:42,367 - INFO - 📊 VALIDATION 3/5 - Epoch 1, Step 1125
2025-06-08 18:36:42,367 - INFO - ============================================================
2025-06-08 18:36:42,367 - INFO -   • Average Loss: 0.7744
2025-06-08 18:36:42,367 - INFO -   • Sample Average: 0.7650 (10000 samples)
2025-06-08 18:36:55,357 - INFO - ✅ New best model saved in memory
2025-06-08 18:36:55,358 - INFO -   • Early Stop: 0/3
2025-06-08 18:36:55,358 - INFO -   • Best Loss: 0.7744 (epoch 0, step 1125)
2025-06-08 18:36:55,358 - INFO - ============================================================

2025-06-08 18:36:55,359 - INFO - 🏆 New best model! Saving...
2025-06-08 18:36:55,359 - INFO - 💾 Attempting to save model to: /root/llama3.2-3b-sft-training/best/model
2025-06-08 18:36:55,359 - INFO -    Trying standard safe save...
2025-06-08 18:36:55,364 - WARNING -    Standard safe save failed: cannot import name 'DTensor' from 'torch.distributed.tensor' (/usr/local/lib/python3.11/dist-packages/torch/distributed/tensor/__init__.py)
2025-06-08 18:36:55,364 - INFO -    Trying without safe serialization...
2025-06-08 18:36:55,384 - WARNING -    Non-safe save failed: name 'DTensor' is not defined
2025-06-08 18:36:55,384 - INFO -    Trying manual state dict save...
2025-06-08 18:37:08,208 - INFO - ✅ Manual save successful!
2025-06-08 18:37:48,986 - INFO - 💾 Checkpoint saved: /root/llama3.2-3b-sft-training/checkpoints/checkpoint-best.pt
2025-06-08 18:38:15,201 - INFO - 🚀 Step 1130 | Loss: 0.7408 | LR: 1.85e-05
2025-06-08 18:38:15,201 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:39:08,290 - INFO - 🚀 Step 1140 | Loss: 0.7382 | LR: 1.85e-05
2025-06-08 18:39:08,290 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:40:02,344 - INFO - 🚀 Step 1150 | Loss: 0.7747 | LR: 1.84e-05
2025-06-08 18:40:02,344 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:40:53,190 - INFO - 🚀 Step 1160 | Loss: 0.7277 | LR: 1.84e-05
2025-06-08 18:40:53,190 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:41:43,433 - INFO - 🚀 Step 1170 | Loss: 0.7635 | LR: 1.84e-05
2025-06-08 18:41:43,433 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:42:37,486 - INFO - 🚀 Step 1180 | Loss: 0.8045 | LR: 1.84e-05
2025-06-08 18:42:37,486 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:43:28,733 - INFO - 🚀 Step 1190 | Loss: 0.7426 | LR: 1.83e-05
2025-06-08 18:43:28,733 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:44:23,181 - INFO - 🚀 Step 1200 | Loss: 0.8415 | LR: 1.83e-05
2025-06-08 18:44:23,181 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:45:15,883 - INFO - 🚀 Step 1210 | Loss: 0.7544 | LR: 1.83e-05
2025-06-08 18:45:15,884 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:46:07,376 - INFO - 🚀 Step 1220 | Loss: 0.7502 | LR: 1.82e-05
2025-06-08 18:46:07,377 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:47:00,104 - INFO - 🚀 Step 1230 | Loss: 0.6851 | LR: 1.82e-05
2025-06-08 18:47:00,105 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:47:51,625 - INFO - 🚀 Step 1240 | Loss: 0.7576 | LR: 1.82e-05
2025-06-08 18:47:51,625 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:48:44,275 - INFO - 🚀 Step 1250 | Loss: 0.7630 | LR: 1.81e-05
2025-06-08 18:48:44,275 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:49:36,354 - INFO - 🚀 Step 1260 | Loss: 0.7638 | LR: 1.81e-05
2025-06-08 18:49:36,354 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:50:30,610 - INFO - 🚀 Step 1270 | Loss: 0.7718 | LR: 1.81e-05
2025-06-08 18:50:30,610 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:51:22,568 - INFO - 🚀 Step 1280 | Loss: 0.7723 | LR: 1.80e-05
2025-06-08 18:51:22,568 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:52:13,273 - INFO - 🚀 Step 1290 | Loss: 0.7469 | LR: 1.80e-05
2025-06-08 18:52:13,273 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:53:03,581 - INFO - 🚀 Step 1300 | Loss: 0.7579 | LR: 1.80e-05
2025-06-08 18:53:03,581 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:53:50,489 - INFO - 🚀 Step 1310 | Loss: 0.7380 | LR: 1.79e-05
2025-06-08 18:53:50,489 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:54:43,172 - INFO - 🚀 Step 1320 | Loss: 0.7397 | LR: 1.79e-05
2025-06-08 18:54:43,172 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:55:36,299 - INFO - 🚀 Step 1330 | Loss: 0.7577 | LR: 1.78e-05
2025-06-08 18:55:36,300 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:56:28,242 - INFO - 🚀 Step 1340 | Loss: 0.7543 | LR: 1.78e-05
2025-06-08 18:56:28,242 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:57:19,070 - INFO - 🚀 Step 1350 | Loss: 0.7669 | LR: 1.78e-05
2025-06-08 18:57:19,070 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:58:12,819 - INFO - 🚀 Step 1360 | Loss: 0.7516 | LR: 1.77e-05
2025-06-08 18:58:12,819 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:59:01,009 - INFO - 🚀 Step 1370 | Loss: 0.7515 | LR: 1.77e-05
2025-06-08 18:59:01,010 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 18:59:53,074 - INFO - 🚀 Step 1380 | Loss: 0.7097 | LR: 1.77e-05
2025-06-08 18:59:53,074 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:00:46,630 - INFO - 🚀 Step 1390 | Loss: 0.7488 | LR: 1.76e-05
2025-06-08 19:00:46,630 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:01:39,043 - INFO - 🚀 Step 1400 | Loss: 0.7377 | LR: 1.76e-05
2025-06-08 19:01:39,044 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:02:29,642 - INFO - 🚀 Step 1410 | Loss: 0.6946 | LR: 1.76e-05
2025-06-08 19:02:29,642 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:03:22,779 - INFO - 🚀 Step 1420 | Loss: 0.7365 | LR: 1.75e-05
2025-06-08 19:03:22,779 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:04:15,180 - INFO - 🚀 Step 1430 | Loss: 0.7417 | LR: 1.75e-05
2025-06-08 19:04:15,180 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:05:06,234 - INFO - 🚀 Step 1440 | Loss: 0.6859 | LR: 1.74e-05
2025-06-08 19:05:06,234 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:05:58,903 - INFO - 🚀 Step 1450 | Loss: 0.7128 | LR: 1.74e-05
2025-06-08 19:05:58,903 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:06:51,942 - INFO - 🚀 Step 1460 | Loss: 0.7316 | LR: 1.74e-05
2025-06-08 19:06:51,942 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:07:44,590 - INFO - 🚀 Step 1470 | Loss: 0.7321 | LR: 1.73e-05
2025-06-08 19:07:44,590 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:08:36,874 - INFO - 🚀 Step 1480 | Loss: 0.7299 | LR: 1.73e-05
2025-06-08 19:08:36,874 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:09:26,931 - INFO - 🚀 Step 1490 | Loss: 0.7364 | LR: 1.72e-05
2025-06-08 19:09:26,931 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:14:57,329 - INFO - 
============================================================
2025-06-08 19:14:57,329 - INFO - 📊 VALIDATION 4/5 - Epoch 1, Step 1500
2025-06-08 19:14:57,329 - INFO - ============================================================
2025-06-08 19:14:57,329 - INFO -   • Average Loss: 0.7262
2025-06-08 19:14:57,329 - INFO -   • Sample Average: 0.7210 (10000 samples)
2025-06-08 19:15:11,149 - INFO - ✅ New best model saved in memory
2025-06-08 19:15:11,150 - INFO -   • Early Stop: 0/3
2025-06-08 19:15:11,150 - INFO -   • Best Loss: 0.7262 (epoch 0, step 1500)
2025-06-08 19:15:11,150 - INFO - ============================================================

2025-06-08 19:15:11,152 - INFO - 🏆 New best model! Saving...
2025-06-08 19:15:11,152 - INFO - 💾 Attempting to save model to: /root/llama3.2-3b-sft-training/best/model
2025-06-08 19:15:11,152 - INFO -    Trying standard safe save...
2025-06-08 19:15:11,158 - WARNING -    Standard safe save failed: cannot import name 'DTensor' from 'torch.distributed.tensor' (/usr/local/lib/python3.11/dist-packages/torch/distributed/tensor/__init__.py)
2025-06-08 19:15:11,158 - INFO -    Trying without safe serialization...
2025-06-08 19:15:11,179 - WARNING -    Non-safe save failed: name 'DTensor' is not defined
2025-06-08 19:15:11,179 - INFO -    Trying manual state dict save...
2025-06-08 19:15:25,553 - INFO - ✅ Manual save successful!
2025-06-08 19:16:07,702 - INFO - 💾 Checkpoint saved: /root/llama3.2-3b-sft-training/checkpoints/checkpoint-best.pt
2025-06-08 19:16:07,706 - INFO - 🚀 Step 1500 | Loss: 0.7418 | LR: 1.72e-05
2025-06-08 19:16:07,706 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:16:59,129 - INFO - 🚀 Step 1510 | Loss: 0.7416 | LR: 1.72e-05
2025-06-08 19:16:59,130 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:17:52,310 - INFO - 🚀 Step 1520 | Loss: 0.7388 | LR: 1.71e-05
2025-06-08 19:17:52,310 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:18:42,164 - INFO - 🚀 Step 1530 | Loss: 0.6953 | LR: 1.71e-05
2025-06-08 19:18:42,164 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:19:35,169 - INFO - 🚀 Step 1540 | Loss: 0.6752 | LR: 1.70e-05
2025-06-08 19:19:35,170 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:20:27,823 - INFO - 🚀 Step 1550 | Loss: 0.7178 | LR: 1.70e-05
2025-06-08 19:20:27,824 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:21:21,586 - INFO - 🚀 Step 1560 | Loss: 0.7235 | LR: 1.70e-05
2025-06-08 19:21:21,586 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:22:13,437 - INFO - 🚀 Step 1570 | Loss: 0.7282 | LR: 1.69e-05
2025-06-08 19:22:13,437 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:23:03,583 - INFO - 🚀 Step 1580 | Loss: 0.7575 | LR: 1.69e-05
2025-06-08 19:23:03,583 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:23:55,740 - INFO - 🚀 Step 1590 | Loss: 0.6812 | LR: 1.68e-05
2025-06-08 19:23:55,740 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:24:46,548 - INFO - 🚀 Step 1600 | Loss: 0.6872 | LR: 1.68e-05
2025-06-08 19:24:46,548 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:25:39,765 - INFO - 🚀 Step 1610 | Loss: 0.7284 | LR: 1.67e-05
2025-06-08 19:25:39,766 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:26:32,618 - INFO - 🚀 Step 1620 | Loss: 0.7021 | LR: 1.67e-05
2025-06-08 19:26:32,619 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:27:23,882 - INFO - 🚀 Step 1630 | Loss: 0.6756 | LR: 1.67e-05
2025-06-08 19:27:23,882 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:28:19,867 - INFO - 🚀 Step 1640 | Loss: 0.7454 | LR: 1.66e-05
2025-06-08 19:28:19,867 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:29:09,560 - INFO - 🚀 Step 1650 | Loss: 0.7657 | LR: 1.66e-05
2025-06-08 19:29:09,560 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:30:03,629 - INFO - 🚀 Step 1660 | Loss: 0.6944 | LR: 1.65e-05
2025-06-08 19:30:03,629 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:30:55,207 - INFO - 🚀 Step 1670 | Loss: 0.6915 | LR: 1.65e-05
2025-06-08 19:30:55,207 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:31:48,754 - INFO - 🚀 Step 1680 | Loss: 0.7161 | LR: 1.64e-05
2025-06-08 19:31:48,754 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:32:40,005 - INFO - 🚀 Step 1690 | Loss: 0.7450 | LR: 1.64e-05
2025-06-08 19:32:40,005 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:33:33,191 - INFO - 🚀 Step 1700 | Loss: 0.7460 | LR: 1.64e-05
2025-06-08 19:33:33,191 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:34:25,190 - INFO - 🚀 Step 1710 | Loss: 0.7152 | LR: 1.63e-05
2025-06-08 19:34:25,190 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:35:15,500 - INFO - 🚀 Step 1720 | Loss: 0.6973 | LR: 1.63e-05
2025-06-08 19:35:15,500 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:36:06,493 - INFO - 🚀 Step 1730 | Loss: 0.6740 | LR: 1.62e-05
2025-06-08 19:36:06,494 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:36:56,973 - INFO - 🚀 Step 1740 | Loss: 0.7211 | LR: 1.62e-05
2025-06-08 19:36:56,973 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:37:50,209 - INFO - 🚀 Step 1750 | Loss: 0.7160 | LR: 1.61e-05
2025-06-08 19:37:50,209 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:38:44,034 - INFO - 🚀 Step 1760 | Loss: 0.6769 | LR: 1.61e-05
2025-06-08 19:38:44,035 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:39:33,704 - INFO - 🚀 Step 1770 | Loss: 0.7310 | LR: 1.60e-05
2025-06-08 19:39:33,704 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:40:27,178 - INFO - 🚀 Step 1780 | Loss: 0.7076 | LR: 1.60e-05
2025-06-08 19:40:27,178 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:41:20,958 - INFO - 🚀 Step 1790 | Loss: 0.7408 | LR: 1.59e-05
2025-06-08 19:41:20,958 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:42:08,647 - INFO - 🚀 Step 1800 | Loss: 0.7049 | LR: 1.59e-05
2025-06-08 19:42:08,647 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:42:58,450 - INFO - 🚀 Step 1810 | Loss: 0.7019 | LR: 1.59e-05
2025-06-08 19:42:58,451 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:43:50,221 - INFO - 🚀 Step 1820 | Loss: 0.7136 | LR: 1.58e-05
2025-06-08 19:43:50,221 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:44:40,958 - INFO - 🚀 Step 1830 | Loss: 0.7930 | LR: 1.58e-05
2025-06-08 19:44:40,959 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:45:33,146 - INFO - 🚀 Step 1840 | Loss: 0.6941 | LR: 1.57e-05
2025-06-08 19:45:33,146 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:46:25,521 - INFO - 🚀 Step 1850 | Loss: 0.6231 | LR: 1.57e-05
2025-06-08 19:46:25,521 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:47:18,721 - INFO - 🚀 Step 1860 | Loss: 0.7175 | LR: 1.56e-05
2025-06-08 19:47:18,721 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:48:12,177 - INFO - 🚀 Step 1870 | Loss: 0.6740 | LR: 1.56e-05
2025-06-08 19:48:12,177 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 19:53:14,238 - INFO - 
============================================================
2025-06-08 19:53:14,239 - INFO - 📊 VALIDATION 5/5 - Epoch 1, Step 1875
2025-06-08 19:53:14,239 - INFO - ============================================================
2025-06-08 19:53:14,239 - INFO -   • Average Loss: 0.6844
2025-06-08 19:53:14,239 - INFO -   • Sample Average: 0.6825 (10000 samples)
2025-06-08 19:53:27,836 - INFO - ✅ New best model saved in memory
2025-06-08 19:53:27,837 - INFO -   • Early Stop: 0/3
2025-06-08 19:53:27,837 - INFO -   • Best Loss: 0.6844 (epoch 0, step 1875)
2025-06-08 19:53:27,837 - INFO - ============================================================

2025-06-08 19:53:27,838 - INFO - 🏆 New best model! Saving...
2025-06-08 19:53:27,838 - INFO - 💾 Attempting to save model to: /root/llama3.2-3b-sft-training/best/model
2025-06-08 19:53:27,838 - INFO -    Trying standard safe save...
2025-06-08 19:53:27,843 - WARNING -    Standard safe save failed: cannot import name 'DTensor' from 'torch.distributed.tensor' (/usr/local/lib/python3.11/dist-packages/torch/distributed/tensor/__init__.py)
2025-06-08 19:53:27,843 - INFO -    Trying without safe serialization...
2025-06-08 19:53:27,863 - WARNING -    Non-safe save failed: name 'DTensor' is not defined
2025-06-08 19:53:27,863 - INFO -    Trying manual state dict save...
2025-06-08 19:53:37,560 - INFO - ✅ Manual save successful!
2025-06-08 19:54:01,353 - INFO - 💾 Checkpoint saved: /root/llama3.2-3b-sft-training/checkpoints/checkpoint-best.pt
2025-06-08 19:54:01,356 - INFO - 💾 Saving epoch 1 checkpoint...
2025-06-08 19:54:22,490 - INFO - 💾 Checkpoint saved: /root/llama3.2-3b-sft-training/checkpoints/checkpoint-epoch-1.pt
2025-06-08 19:54:22,492 - INFO - 🎯 EPOCH 1 COMPLETED
2025-06-08 19:54:22,493 - ERROR - Training failed: name 'epoch_time' is not defined
2025-06-08 19:54:22,494 - ERROR - 🔍 Debug Information:
2025-06-08 19:54:22,494 - ERROR -    • Current directory: /root
2025-06-08 19:54:22,494 - ERROR -    • Dataset exists: True
2025-06-08 19:54:22,494 - ERROR -    • GPU: NVIDIA A100-SXM4-80GB
2025-06-08 19:54:22,494 - ERROR -    • VRAM: 79.3 GB
2025-06-08 20:09:21,067 - INFO - 🚀 Loading model: meta-llama/Llama-3.2-3B
2025-06-08 20:09:21,594 - INFO - ✅ HF authentication successful
2025-06-08 20:09:22,585 - INFO - Tokenizer loaded - vocab_size: 128256
2025-06-08 20:09:23,209 - INFO - ✅ Fixed ALL_PARALLEL_STYLES
2025-06-08 20:09:23,557 - ERROR - Model loading failed: LlamaForCausalLM.__init__() got an unexpected keyword argument 'use_cache'
2025-06-08 20:09:24,177 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 20:09:25,772 - INFO - ✅ Model loaded with alternative method (float32)
2025-06-08 20:09:25,774 - INFO - ✅ Model loaded - 3,212,749,824 parameters
2025-06-08 20:09:25,774 - INFO -    GPU: NVIDIA A100-SXM4-80GB - 79.3GB VRAM
2025-06-08 20:09:25,774 - INFO - 📁 Loading SFT dataset: /root/codexglue_train.json
2025-06-08 20:09:26,391 - INFO - ✅ Loaded 100000 samples
2025-06-08 20:09:26,413 - INFO - 
📊 Train/Val Split:
2025-06-08 20:09:26,413 - INFO - 🚂 TRAIN SET: 90000 samples
2025-06-08 20:09:26,413 - INFO - 🧪 VALIDATION SET: 10000 samples
2025-06-08 20:09:26,413 - INFO - 
🔍 Validation Set Examples (first 3):
2025-06-08 20:09:26,413 - INFO -   [0] ID: 3813
2025-06-08 20:09:26,413 - INFO -        NL: get the factory that is used by default for the #create method is invoked . concode_field_sep Object...
2025-06-08 20:09:26,413 - INFO -   [1] ID: 99183
2025-06-08 20:09:26,413 - INFO -        NL: render exceptions . sets the response status accordingly to note bad requests . concode_field_sep Pl...
2025-06-08 20:09:26,413 - INFO -   [2] ID: 80737
2025-06-08 20:09:26,413 - INFO -        NL: retrieves diagnostics information preserved in the history file concode_field_sep Iterable<String> N...
2025-06-08 20:09:26,413 - INFO - 🎯 Creating SFT Dataset:
2025-06-08 20:09:26,413 - INFO -    Total samples: 90000
2025-06-08 20:09:26,413 - INFO - 🔥 PRE-TOKENIZING ALL SAMPLES...
2025-06-08 20:10:01,975 - INFO - ✅ Tokenization complete: 90000 entries
2025-06-08 20:10:01,975 - INFO - 🎯 Creating SFT Dataset:
2025-06-08 20:10:01,975 - INFO -    Total samples: 10000
2025-06-08 20:10:01,975 - INFO - 🔥 PRE-TOKENIZING ALL SAMPLES...
2025-06-08 20:10:06,460 - INFO - ✅ Tokenization complete: 10000 entries
2025-06-08 20:10:06,463 - INFO - 🎯 Optimizer setup:
2025-06-08 20:10:06,463 - INFO -    Steps per epoch: 1875
2025-06-08 20:10:06,463 - INFO -    Total steps: 5625
2025-06-08 20:10:06,463 - INFO -    Warmup steps: 168
2025-06-08 20:10:06,463 - INFO -    Eval frequency: every 375 steps (5x per epoch)
2025-06-08 20:10:06,463 - INFO - 🚀 Starting SFT-only training...
2025-06-08 20:10:06,463 - INFO -    📊 Dataset: codexglue_train.json
2025-06-08 20:10:06,463 - INFO -    🎯 Each sample appears exactly once per epoch
2025-06-08 20:10:06,463 - INFO -    🔧 Early stopping (patience=3)
2025-06-08 20:10:06,463 - INFO -    📈 5 evaluations per epoch
2025-06-08 20:10:06,463 - INFO -    💾 Best model saved based on validation loss
2025-06-08 20:10:06,463 - INFO - 
🎯 EPOCH 1/3
2025-06-08 20:27:07,090 - INFO - 🚀 Loading model: meta-llama/Llama-3.2-3B
2025-06-08 20:27:07,274 - INFO - ✅ HF authentication successful
2025-06-08 20:27:08,310 - INFO - Tokenizer loaded - vocab_size: 128256
2025-06-08 20:27:08,883 - INFO - ✅ Fixed ALL_PARALLEL_STYLES
2025-06-08 20:27:09,197 - ERROR - Model loading failed: LlamaForCausalLM.__init__() got an unexpected keyword argument 'use_cache'
2025-06-08 20:27:09,564 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-06-08 20:27:10,844 - INFO - ✅ Model loaded with alternative method (float32)
2025-06-08 20:27:10,846 - INFO - ✅ Model loaded - 3,212,749,824 parameters
2025-06-08 20:27:10,847 - INFO -    GPU: NVIDIA A100-SXM4-80GB - 79.3GB VRAM
2025-06-08 20:27:10,847 - INFO - 📁 Loading SFT dataset: /root/codexglue_train.json
2025-06-08 20:27:11,502 - INFO - ✅ Loaded 100000 samples
2025-06-08 20:27:11,524 - INFO - 
📊 Train/Val Split:
2025-06-08 20:27:11,524 - INFO - 🚂 TRAIN SET: 90000 samples
2025-06-08 20:27:11,524 - INFO - 🧪 VALIDATION SET: 10000 samples
2025-06-08 20:27:11,524 - INFO - 
🔍 Validation Set Examples (first 3):
2025-06-08 20:27:11,524 - INFO -   [0] ID: 3813
2025-06-08 20:27:11,524 - INFO -        NL: get the factory that is used by default for the #create method is invoked . concode_field_sep Object...
2025-06-08 20:27:11,524 - INFO -   [1] ID: 99183
2025-06-08 20:27:11,525 - INFO -        NL: render exceptions . sets the response status accordingly to note bad requests . concode_field_sep Pl...
2025-06-08 20:27:11,525 - INFO -   [2] ID: 80737
2025-06-08 20:27:11,525 - INFO -        NL: retrieves diagnostics information preserved in the history file concode_field_sep Iterable<String> N...
2025-06-08 20:27:11,525 - INFO - 🎯 Creating SFT Dataset:
2025-06-08 20:27:11,525 - INFO -    Total samples: 90000
2025-06-08 20:27:11,525 - INFO - 🔥 PRE-TOKENIZING ALL SAMPLES...
2025-06-08 20:27:47,728 - INFO - ✅ Tokenization complete: 90000 entries
2025-06-08 20:27:47,729 - INFO - 🎯 Creating SFT Dataset:
2025-06-08 20:27:47,729 - INFO -    Total samples: 10000
2025-06-08 20:27:47,729 - INFO - 🔥 PRE-TOKENIZING ALL SAMPLES...
2025-06-08 20:27:52,374 - INFO - ✅ Tokenization complete: 10000 entries
2025-06-08 20:27:52,376 - INFO - 🎯 Optimizer setup:
2025-06-08 20:27:52,376 - INFO -    Steps per epoch: 1875
2025-06-08 20:27:52,376 - INFO -    Total steps: 5625
2025-06-08 20:27:52,376 - INFO -    Warmup steps: 168
2025-06-08 20:27:52,376 - INFO -    Eval frequency: every 375 steps (5x per epoch)
2025-06-08 20:27:52,376 - INFO - 📂 Loading checkpoint: /root/llama3.2-3b-sft-training/checkpoints/checkpoint-epoch-1.pt
2025-06-08 20:28:12,785 - INFO - ✅ Model state loaded
2025-06-08 20:28:14,853 - INFO - ✅ Optimizer state loaded
2025-06-08 20:28:14,853 - INFO - ✅ Scheduler state loaded
2025-06-08 20:28:14,853 - INFO - 📊 Resuming from epoch 1, step 1875
2025-06-08 20:28:17,308 - INFO - 🚀 Starting SFT-only training...
2025-06-08 20:28:17,312 - INFO -    📊 Dataset: codexglue_train.json
2025-06-08 20:28:17,312 - INFO -    🎯 Each sample appears exactly once per epoch
2025-06-08 20:28:17,312 - INFO -    🔧 Early stopping (patience=3)
2025-06-08 20:28:17,312 - INFO -    📈 5 evaluations per epoch
2025-06-08 20:28:17,312 - INFO -    💾 Best model saved based on validation loss
2025-06-08 20:28:17,312 - INFO -    🔄 Resuming from epoch 1, step 1875
2025-06-08 20:28:17,312 - INFO - 
🎯 EPOCH 2/3
2025-06-08 20:28:44,152 - INFO - 🚀 Step 1880 | Loss: 0.6310 | LR: 1.55e-05
2025-06-08 20:28:44,153 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:29:35,415 - INFO - 🚀 Step 1890 | Loss: 0.6571 | LR: 1.55e-05
2025-06-08 20:29:35,415 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:30:28,044 - INFO - 🚀 Step 1900 | Loss: 0.6740 | LR: 1.54e-05
2025-06-08 20:30:28,044 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:31:23,783 - INFO - 🚀 Step 1910 | Loss: 0.6216 | LR: 1.54e-05
2025-06-08 20:31:23,783 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:32:15,714 - INFO - 🚀 Step 1920 | Loss: 0.6672 | LR: 1.53e-05
2025-06-08 20:32:15,715 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:33:10,425 - INFO - 🚀 Step 1930 | Loss: 0.6474 | LR: 1.53e-05
2025-06-08 20:33:10,426 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:34:03,837 - INFO - 🚀 Step 1940 | Loss: 0.6494 | LR: 1.52e-05
2025-06-08 20:34:03,837 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:34:55,535 - INFO - 🚀 Step 1950 | Loss: 0.6645 | LR: 1.52e-05
2025-06-08 20:34:55,535 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:35:48,286 - INFO - 🚀 Step 1960 | Loss: 0.6320 | LR: 1.51e-05
2025-06-08 20:35:48,286 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:36:40,421 - INFO - 🚀 Step 1970 | Loss: 0.6378 | LR: 1.51e-05
2025-06-08 20:36:40,422 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:37:32,268 - INFO - 🚀 Step 1980 | Loss: 0.5781 | LR: 1.50e-05
2025-06-08 20:37:32,268 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:38:25,534 - INFO - 🚀 Step 1990 | Loss: 0.5987 | LR: 1.50e-05
2025-06-08 20:38:25,535 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:39:16,573 - INFO - 🚀 Step 2000 | Loss: 0.5725 | LR: 1.49e-05
2025-06-08 20:39:16,573 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:40:10,245 - INFO - 🚀 Step 2010 | Loss: 0.5677 | LR: 1.49e-05
2025-06-08 20:40:10,245 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:41:01,739 - INFO - 🚀 Step 2020 | Loss: 0.5633 | LR: 1.48e-05
2025-06-08 20:41:01,739 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:41:56,242 - INFO - 🚀 Step 2030 | Loss: 0.5454 | LR: 1.48e-05
2025-06-08 20:41:56,242 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:42:50,037 - INFO - 🚀 Step 2040 | Loss: 0.5986 | LR: 1.47e-05
2025-06-08 20:42:50,037 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:43:43,010 - INFO - 🚀 Step 2050 | Loss: 0.5695 | LR: 1.47e-05
2025-06-08 20:43:43,010 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:44:34,188 - INFO - 🚀 Step 2060 | Loss: 0.6003 | LR: 1.46e-05
2025-06-08 20:44:34,188 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:45:26,223 - INFO - 🚀 Step 2070 | Loss: 0.5173 | LR: 1.46e-05
2025-06-08 20:45:26,223 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:46:18,400 - INFO - 🚀 Step 2080 | Loss: 0.5560 | LR: 1.45e-05
2025-06-08 20:46:18,400 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:47:12,531 - INFO - 🚀 Step 2090 | Loss: 0.5372 | LR: 1.45e-05
2025-06-08 20:47:12,531 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:48:04,441 - INFO - 🚀 Step 2100 | Loss: 0.5362 | LR: 1.44e-05
2025-06-08 20:48:04,441 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:48:55,175 - INFO - 🚀 Step 2110 | Loss: 0.5537 | LR: 1.44e-05
2025-06-08 20:48:55,175 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:49:51,024 - INFO - 🚀 Step 2120 | Loss: 0.5816 | LR: 1.43e-05
2025-06-08 20:49:51,024 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:50:42,398 - INFO - 🚀 Step 2130 | Loss: 0.5455 | LR: 1.43e-05
2025-06-08 20:50:42,398 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:51:34,984 - INFO - 🚀 Step 2140 | Loss: 0.5515 | LR: 1.42e-05
2025-06-08 20:51:34,984 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:52:24,175 - INFO - 🚀 Step 2150 | Loss: 0.4879 | LR: 1.42e-05
2025-06-08 20:52:24,175 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:53:17,285 - INFO - 🚀 Step 2160 | Loss: 0.5458 | LR: 1.41e-05
2025-06-08 20:53:17,286 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:54:10,952 - INFO - 🚀 Step 2170 | Loss: 0.5542 | LR: 1.41e-05
2025-06-08 20:54:10,953 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:55:03,661 - INFO - 🚀 Step 2180 | Loss: 0.5476 | LR: 1.40e-05
2025-06-08 20:55:03,661 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:55:57,124 - INFO - 🚀 Step 2190 | Loss: 0.5714 | LR: 1.40e-05
2025-06-08 20:55:57,124 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:56:52,320 - INFO - 🚀 Step 2200 | Loss: 0.5333 | LR: 1.39e-05
2025-06-08 20:56:52,320 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:57:46,293 - INFO - 🚀 Step 2210 | Loss: 0.5146 | LR: 1.39e-05
2025-06-08 20:57:46,294 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:58:39,860 - INFO - 🚀 Step 2220 | Loss: 0.4936 | LR: 1.38e-05
2025-06-08 20:58:39,860 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 20:59:30,480 - INFO - 🚀 Step 2230 | Loss: 0.5360 | LR: 1.37e-05
2025-06-08 20:59:30,480 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:00:24,595 - INFO - 🚀 Step 2240 | Loss: 0.5140 | LR: 1.37e-05
2025-06-08 21:00:24,595 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:05:52,530 - INFO - 
============================================================
2025-06-08 21:05:52,531 - INFO - 📊 VALIDATION 1/5 - Epoch 2, Step 2250
2025-06-08 21:05:52,531 - INFO - ============================================================
2025-06-08 21:05:52,531 - INFO -   • Average Loss: 0.6631
2025-06-08 21:05:52,531 - INFO -   • Sample Average: 0.6635 (10000 samples)
2025-06-08 21:06:03,599 - INFO - ✅ New best model saved in memory
2025-06-08 21:06:03,600 - INFO -   • Early Stop: 0/3
2025-06-08 21:06:03,600 - INFO -   • Best Loss: 0.6631 (epoch 1, step 2250)
2025-06-08 21:06:03,600 - INFO - ============================================================

2025-06-08 21:06:03,600 - INFO - 🏆 New best model! Saving...
2025-06-08 21:06:03,601 - INFO - 💾 Attempting to save model to: /root/llama3.2-3b-sft-training/best/model
2025-06-08 21:06:03,601 - INFO -    Trying standard safe save...
2025-06-08 21:06:03,698 - WARNING -    Standard safe save failed: cannot import name 'DTensor' from 'torch.distributed.tensor' (/usr/local/lib/python3.11/dist-packages/torch/distributed/tensor/__init__.py)
2025-06-08 21:06:03,698 - INFO -    Trying without safe serialization...
2025-06-08 21:06:03,719 - WARNING -    Non-safe save failed: name 'DTensor' is not defined
2025-06-08 21:06:03,719 - INFO -    Trying manual state dict save...
2025-06-08 21:06:15,719 - INFO - ✅ Manual save successful!
2025-06-08 21:06:51,986 - INFO - 💾 Checkpoint saved: /root/llama3.2-3b-sft-training/checkpoints/checkpoint-best.pt
2025-06-08 21:06:51,988 - INFO - 🚀 Step 2250 | Loss: 0.5272 | LR: 1.36e-05
2025-06-08 21:06:51,988 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:07:46,208 - INFO - 🚀 Step 2260 | Loss: 0.5142 | LR: 1.36e-05
2025-06-08 21:07:46,208 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:08:36,145 - INFO - 🚀 Step 2270 | Loss: 0.5154 | LR: 1.35e-05
2025-06-08 21:08:36,145 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:09:29,010 - INFO - 🚀 Step 2280 | Loss: 0.5791 | LR: 1.35e-05
2025-06-08 21:09:29,010 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:10:20,666 - INFO - 🚀 Step 2290 | Loss: 0.4505 | LR: 1.34e-05
2025-06-08 21:10:20,666 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:11:11,810 - INFO - 🚀 Step 2300 | Loss: 0.5737 | LR: 1.34e-05
2025-06-08 21:11:11,810 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:12:02,103 - INFO - 🚀 Step 2310 | Loss: 0.5304 | LR: 1.33e-05
2025-06-08 21:12:02,103 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:12:54,979 - INFO - 🚀 Step 2320 | Loss: 0.5190 | LR: 1.33e-05
2025-06-08 21:12:54,980 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:13:46,268 - INFO - 🚀 Step 2330 | Loss: 0.5413 | LR: 1.32e-05
2025-06-08 21:13:46,268 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:14:38,085 - INFO - 🚀 Step 2340 | Loss: 0.5066 | LR: 1.31e-05
2025-06-08 21:14:38,086 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:15:29,779 - INFO - 🚀 Step 2350 | Loss: 0.4826 | LR: 1.31e-05
2025-06-08 21:15:29,780 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:16:19,082 - INFO - 🚀 Step 2360 | Loss: 0.5445 | LR: 1.30e-05
2025-06-08 21:16:19,082 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:17:09,667 - INFO - 🚀 Step 2370 | Loss: 0.5210 | LR: 1.30e-05
2025-06-08 21:17:09,668 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:18:01,788 - INFO - 🚀 Step 2380 | Loss: 0.5173 | LR: 1.29e-05
2025-06-08 21:18:01,789 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:18:55,826 - INFO - 🚀 Step 2390 | Loss: 0.5011 | LR: 1.29e-05
2025-06-08 21:18:55,826 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:19:47,285 - INFO - 🚀 Step 2400 | Loss: 0.4985 | LR: 1.28e-05
2025-06-08 21:19:47,285 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:20:40,471 - INFO - 🚀 Step 2410 | Loss: 0.5221 | LR: 1.28e-05
2025-06-08 21:20:40,471 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:21:32,541 - INFO - 🚀 Step 2420 | Loss: 0.5030 | LR: 1.27e-05
2025-06-08 21:21:32,541 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:22:28,145 - INFO - 🚀 Step 2430 | Loss: 0.4759 | LR: 1.27e-05
2025-06-08 21:22:28,145 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:23:16,371 - INFO - 🚀 Step 2440 | Loss: 0.5127 | LR: 1.26e-05
2025-06-08 21:23:16,371 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:24:08,068 - INFO - 🚀 Step 2450 | Loss: 0.4798 | LR: 1.25e-05
2025-06-08 21:24:08,068 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:25:01,074 - INFO - 🚀 Step 2460 | Loss: 0.5094 | LR: 1.25e-05
2025-06-08 21:25:01,074 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:25:55,738 - INFO - 🚀 Step 2470 | Loss: 0.4915 | LR: 1.24e-05
2025-06-08 21:25:55,738 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:26:49,820 - INFO - 🚀 Step 2480 | Loss: 0.4696 | LR: 1.24e-05
2025-06-08 21:26:49,821 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:27:41,295 - INFO - 🚀 Step 2490 | Loss: 0.4952 | LR: 1.23e-05
2025-06-08 21:27:41,295 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:28:35,707 - INFO - 🚀 Step 2500 | Loss: 0.5083 | LR: 1.23e-05
2025-06-08 21:28:35,707 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:29:28,168 - INFO - 🚀 Step 2510 | Loss: 0.4269 | LR: 1.22e-05
2025-06-08 21:29:28,168 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:30:19,566 - INFO - 🚀 Step 2520 | Loss: 0.4731 | LR: 1.22e-05
2025-06-08 21:30:19,566 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:31:12,020 - INFO - 🚀 Step 2530 | Loss: 0.4875 | LR: 1.21e-05
2025-06-08 21:31:12,020 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:32:05,912 - INFO - 🚀 Step 2540 | Loss: 0.4606 | LR: 1.20e-05
2025-06-08 21:32:05,913 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:33:00,393 - INFO - 🚀 Step 2550 | Loss: 0.4836 | LR: 1.20e-05
2025-06-08 21:33:00,394 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:33:54,055 - INFO - 🚀 Step 2560 | Loss: 0.4822 | LR: 1.19e-05
2025-06-08 21:33:54,055 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:34:44,316 - INFO - 🚀 Step 2570 | Loss: 0.4599 | LR: 1.19e-05
2025-06-08 21:34:44,316 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:35:35,977 - INFO - 🚀 Step 2580 | Loss: 0.5003 | LR: 1.18e-05
2025-06-08 21:35:35,977 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:36:24,777 - INFO - 🚀 Step 2590 | Loss: 0.4776 | LR: 1.18e-05
2025-06-08 21:36:24,777 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:37:15,741 - INFO - 🚀 Step 2600 | Loss: 0.4768 | LR: 1.17e-05
2025-06-08 21:37:15,742 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:38:08,905 - INFO - 🚀 Step 2610 | Loss: 0.4416 | LR: 1.16e-05
2025-06-08 21:38:08,905 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:39:02,980 - INFO - 🚀 Step 2620 | Loss: 0.5003 | LR: 1.16e-05
2025-06-08 21:39:02,980 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:44:05,408 - INFO - 
============================================================
2025-06-08 21:44:05,409 - INFO - 📊 VALIDATION 2/5 - Epoch 2, Step 2625
2025-06-08 21:44:05,409 - INFO - ============================================================
2025-06-08 21:44:05,409 - INFO -   • Average Loss: 0.6452
2025-06-08 21:44:05,409 - INFO -   • Sample Average: 0.6477 (10000 samples)
2025-06-08 21:44:18,130 - INFO - ✅ New best model saved in memory
2025-06-08 21:44:18,130 - INFO -   • Early Stop: 0/3
2025-06-08 21:44:18,131 - INFO -   • Best Loss: 0.6452 (epoch 1, step 2625)
2025-06-08 21:44:18,131 - INFO - ============================================================

2025-06-08 21:44:18,131 - INFO - 🏆 New best model! Saving...
2025-06-08 21:44:18,132 - INFO - 💾 Attempting to save model to: /root/llama3.2-3b-sft-training/best/model
2025-06-08 21:44:18,132 - INFO -    Trying standard safe save...
2025-06-08 21:44:18,136 - WARNING -    Standard safe save failed: cannot import name 'DTensor' from 'torch.distributed.tensor' (/usr/local/lib/python3.11/dist-packages/torch/distributed/tensor/__init__.py)
2025-06-08 21:44:18,136 - INFO -    Trying without safe serialization...
2025-06-08 21:44:18,156 - WARNING -    Non-safe save failed: name 'DTensor' is not defined
2025-06-08 21:44:18,157 - INFO -    Trying manual state dict save...
2025-06-08 21:44:25,631 - INFO - ✅ Manual save successful!
2025-06-08 21:44:50,151 - INFO - 💾 Checkpoint saved: /root/llama3.2-3b-sft-training/checkpoints/checkpoint-best.pt
2025-06-08 21:45:15,158 - INFO - 🚀 Step 2630 | Loss: 0.4616 | LR: 1.15e-05
2025-06-08 21:45:15,158 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:46:09,824 - INFO - 🚀 Step 2640 | Loss: 0.5191 | LR: 1.15e-05
2025-06-08 21:46:09,824 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:47:03,742 - INFO - 🚀 Step 2650 | Loss: 0.4399 | LR: 1.14e-05
2025-06-08 21:47:03,742 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:47:52,243 - INFO - 🚀 Step 2660 | Loss: 0.4657 | LR: 1.14e-05
2025-06-08 21:47:52,243 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:48:43,397 - INFO - 🚀 Step 2670 | Loss: 0.4238 | LR: 1.13e-05
2025-06-08 21:48:43,397 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:49:39,350 - INFO - 🚀 Step 2680 | Loss: 0.4655 | LR: 1.12e-05
2025-06-08 21:49:39,350 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:50:33,178 - INFO - 🚀 Step 2690 | Loss: 0.5060 | LR: 1.12e-05
2025-06-08 21:50:33,178 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:51:25,456 - INFO - 🚀 Step 2700 | Loss: 0.4616 | LR: 1.11e-05
2025-06-08 21:51:25,456 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:52:15,773 - INFO - 🚀 Step 2710 | Loss: 0.4468 | LR: 1.11e-05
2025-06-08 21:52:15,773 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:53:06,054 - INFO - 🚀 Step 2720 | Loss: 0.4631 | LR: 1.10e-05
2025-06-08 21:53:06,054 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:53:59,728 - INFO - 🚀 Step 2730 | Loss: 0.4752 | LR: 1.10e-05
2025-06-08 21:53:59,729 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:54:54,028 - INFO - 🚀 Step 2740 | Loss: 0.4840 | LR: 1.09e-05
2025-06-08 21:54:54,028 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:55:48,042 - INFO - 🚀 Step 2750 | Loss: 0.4592 | LR: 1.08e-05
2025-06-08 21:55:48,042 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:56:41,117 - INFO - 🚀 Step 2760 | Loss: 0.4850 | LR: 1.08e-05
2025-06-08 21:56:41,117 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:57:32,667 - INFO - 🚀 Step 2770 | Loss: 0.4924 | LR: 1.07e-05
2025-06-08 21:57:32,668 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:58:25,590 - INFO - 🚀 Step 2780 | Loss: 0.4458 | LR: 1.07e-05
2025-06-08 21:58:25,590 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 21:59:17,032 - INFO - 🚀 Step 2790 | Loss: 0.4486 | LR: 1.06e-05
2025-06-08 21:59:17,033 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:00:13,369 - INFO - 🚀 Step 2800 | Loss: 0.5018 | LR: 1.06e-05
2025-06-08 22:00:13,369 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:01:07,435 - INFO - 🚀 Step 2810 | Loss: 0.4473 | LR: 1.05e-05
2025-06-08 22:01:07,435 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:01:58,768 - INFO - 🚀 Step 2820 | Loss: 0.4632 | LR: 1.04e-05
2025-06-08 22:01:58,768 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:02:48,130 - INFO - 🚀 Step 2830 | Loss: 0.4386 | LR: 1.04e-05
2025-06-08 22:02:48,130 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:03:40,695 - INFO - 🚀 Step 2840 | Loss: 0.4451 | LR: 1.03e-05
2025-06-08 22:03:40,696 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:04:31,555 - INFO - 🚀 Step 2850 | Loss: 0.4301 | LR: 1.03e-05
2025-06-08 22:04:31,555 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:05:22,754 - INFO - 🚀 Step 2860 | Loss: 0.4603 | LR: 1.02e-05
2025-06-08 22:05:22,754 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:06:15,641 - INFO - 🚀 Step 2870 | Loss: 0.4449 | LR: 1.02e-05
2025-06-08 22:06:15,642 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:07:07,418 - INFO - 🚀 Step 2880 | Loss: 0.4394 | LR: 1.01e-05
2025-06-08 22:07:07,418 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:07:56,659 - INFO - 🚀 Step 2890 | Loss: 0.4326 | LR: 1.00e-05
2025-06-08 22:07:56,659 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:08:49,173 - INFO - 🚀 Step 2900 | Loss: 0.4264 | LR: 9.98e-06
2025-06-08 22:08:49,173 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:09:40,821 - INFO - 🚀 Step 2910 | Loss: 0.4101 | LR: 9.92e-06
2025-06-08 22:09:40,821 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:10:31,396 - INFO - 🚀 Step 2920 | Loss: 0.4348 | LR: 9.86e-06
2025-06-08 22:10:31,396 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:11:25,328 - INFO - 🚀 Step 2930 | Loss: 0.4648 | LR: 9.81e-06
2025-06-08 22:11:25,328 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:12:15,347 - INFO - 🚀 Step 2940 | Loss: 0.4684 | LR: 9.75e-06
2025-06-08 22:12:15,347 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:13:06,578 - INFO - 🚀 Step 2950 | Loss: 0.4478 | LR: 9.69e-06
2025-06-08 22:13:06,579 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:14:01,407 - INFO - 🚀 Step 2960 | Loss: 0.4456 | LR: 9.63e-06
2025-06-08 22:14:01,407 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:14:53,640 - INFO - 🚀 Step 2970 | Loss: 0.4209 | LR: 9.58e-06
2025-06-08 22:14:53,640 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:15:50,202 - INFO - 🚀 Step 2980 | Loss: 0.4291 | LR: 9.52e-06
2025-06-08 22:15:50,203 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:16:43,293 - INFO - 🚀 Step 2990 | Loss: 0.4090 | LR: 9.46e-06
2025-06-08 22:16:43,294 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:22:11,918 - INFO - 
============================================================
2025-06-08 22:22:11,919 - INFO - 📊 VALIDATION 3/5 - Epoch 2, Step 3000
2025-06-08 22:22:11,919 - INFO - ============================================================
2025-06-08 22:22:11,919 - INFO -   • Average Loss: 0.6272
2025-06-08 22:22:11,919 - INFO -   • Sample Average: 0.6312 (10000 samples)
2025-06-08 22:22:24,293 - INFO - ✅ New best model saved in memory
2025-06-08 22:22:24,294 - INFO -   • Early Stop: 0/3
2025-06-08 22:22:24,294 - INFO -   • Best Loss: 0.6272 (epoch 1, step 3000)
2025-06-08 22:22:24,294 - INFO - ============================================================

2025-06-08 22:22:24,294 - INFO - 🏆 New best model! Saving...
2025-06-08 22:22:24,294 - INFO - 💾 Attempting to save model to: /root/llama3.2-3b-sft-training/best/model
2025-06-08 22:22:24,294 - INFO -    Trying standard safe save...
2025-06-08 22:22:24,298 - WARNING -    Standard safe save failed: cannot import name 'DTensor' from 'torch.distributed.tensor' (/usr/local/lib/python3.11/dist-packages/torch/distributed/tensor/__init__.py)
2025-06-08 22:22:24,298 - INFO -    Trying without safe serialization...
2025-06-08 22:22:24,319 - WARNING -    Non-safe save failed: name 'DTensor' is not defined
2025-06-08 22:22:24,319 - INFO -    Trying manual state dict save...
2025-06-08 22:22:45,862 - INFO - ✅ Manual save successful!
2025-06-08 22:23:25,047 - INFO - 💾 Checkpoint saved: /root/llama3.2-3b-sft-training/checkpoints/checkpoint-best.pt
2025-06-08 22:23:25,049 - INFO - 🚀 Step 3000 | Loss: 0.4547 | LR: 9.40e-06
2025-06-08 22:23:25,049 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:24:16,677 - INFO - 🚀 Step 3010 | Loss: 0.4416 | LR: 9.35e-06
2025-06-08 22:24:16,677 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:25:10,748 - INFO - 🚀 Step 3020 | Loss: 0.4220 | LR: 9.29e-06
2025-06-08 22:25:10,748 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:26:03,965 - INFO - 🚀 Step 3030 | Loss: 0.4235 | LR: 9.23e-06
2025-06-08 22:26:03,965 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:26:53,069 - INFO - 🚀 Step 3040 | Loss: 0.4617 | LR: 9.17e-06
2025-06-08 22:26:53,070 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:27:45,574 - INFO - 🚀 Step 3050 | Loss: 0.4463 | LR: 9.12e-06
2025-06-08 22:27:45,574 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:28:37,179 - INFO - 🚀 Step 3060 | Loss: 0.4794 | LR: 9.06e-06
2025-06-08 22:28:37,179 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:29:29,932 - INFO - 🚀 Step 3070 | Loss: 0.4287 | LR: 9.00e-06
2025-06-08 22:29:29,932 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:30:24,886 - INFO - 🚀 Step 3080 | Loss: 0.4331 | LR: 8.95e-06
2025-06-08 22:30:24,887 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:31:17,162 - INFO - 🚀 Step 3090 | Loss: 0.4393 | LR: 8.89e-06
2025-06-08 22:31:17,163 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:32:08,036 - INFO - 🚀 Step 3100 | Loss: 0.4105 | LR: 8.83e-06
2025-06-08 22:32:08,036 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:33:01,052 - INFO - 🚀 Step 3110 | Loss: 0.4410 | LR: 8.77e-06
2025-06-08 22:33:01,052 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:33:53,120 - INFO - 🚀 Step 3120 | Loss: 0.4103 | LR: 8.72e-06
2025-06-08 22:33:53,121 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:34:43,785 - INFO - 🚀 Step 3130 | Loss: 0.4087 | LR: 8.66e-06
2025-06-08 22:34:43,785 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:35:37,978 - INFO - 🚀 Step 3140 | Loss: 0.4489 | LR: 8.60e-06
2025-06-08 22:35:37,978 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:36:30,834 - INFO - 🚀 Step 3150 | Loss: 0.4307 | LR: 8.55e-06
2025-06-08 22:36:30,834 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:37:23,249 - INFO - 🚀 Step 3160 | Loss: 0.4208 | LR: 8.49e-06
2025-06-08 22:37:23,249 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:38:12,914 - INFO - 🚀 Step 3170 | Loss: 0.4548 | LR: 8.43e-06
2025-06-08 22:38:12,914 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:39:03,162 - INFO - 🚀 Step 3180 | Loss: 0.4753 | LR: 8.38e-06
2025-06-08 22:39:03,162 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:39:50,785 - INFO - 🚀 Step 3190 | Loss: 0.4171 | LR: 8.32e-06
2025-06-08 22:39:50,785 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:40:45,079 - INFO - 🚀 Step 3200 | Loss: 0.3948 | LR: 8.26e-06
2025-06-08 22:40:45,080 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:41:37,673 - INFO - 🚀 Step 3210 | Loss: 0.4526 | LR: 8.20e-06
2025-06-08 22:41:37,673 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:42:28,411 - INFO - 🚀 Step 3220 | Loss: 0.4321 | LR: 8.15e-06
2025-06-08 22:42:28,411 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:43:20,030 - INFO - 🚀 Step 3230 | Loss: 0.3842 | LR: 8.09e-06
2025-06-08 22:43:20,031 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:44:11,864 - INFO - 🚀 Step 3240 | Loss: 0.4035 | LR: 8.04e-06
2025-06-08 22:44:11,864 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:45:02,276 - INFO - 🚀 Step 3250 | Loss: 0.4164 | LR: 7.98e-06
2025-06-08 22:45:02,277 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:45:55,791 - INFO - 🚀 Step 3260 | Loss: 0.4591 | LR: 7.92e-06
2025-06-08 22:45:55,791 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:46:47,778 - INFO - 🚀 Step 3270 | Loss: 0.4641 | LR: 7.87e-06
2025-06-08 22:46:47,778 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:47:40,041 - INFO - 🚀 Step 3280 | Loss: 0.4735 | LR: 7.81e-06
2025-06-08 22:47:40,041 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:48:31,074 - INFO - 🚀 Step 3290 | Loss: 0.4417 | LR: 7.75e-06
2025-06-08 22:48:31,074 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:49:24,427 - INFO - 🚀 Step 3300 | Loss: 0.4213 | LR: 7.70e-06
2025-06-08 22:49:24,427 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:50:16,364 - INFO - 🚀 Step 3310 | Loss: 0.3863 | LR: 7.64e-06
2025-06-08 22:50:16,364 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:51:07,188 - INFO - 🚀 Step 3320 | Loss: 0.4662 | LR: 7.59e-06
2025-06-08 22:51:07,188 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:52:00,731 - INFO - 🚀 Step 3330 | Loss: 0.4089 | LR: 7.53e-06
2025-06-08 22:52:00,732 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:52:53,230 - INFO - 🚀 Step 3340 | Loss: 0.3783 | LR: 7.47e-06
2025-06-08 22:52:53,231 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:53:44,569 - INFO - 🚀 Step 3350 | Loss: 0.4049 | LR: 7.42e-06
2025-06-08 22:53:44,569 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:54:38,346 - INFO - 🚀 Step 3360 | Loss: 0.4255 | LR: 7.36e-06
2025-06-08 22:54:38,347 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 22:55:27,901 - INFO - 🚀 Step 3370 | Loss: 0.4084 | LR: 7.31e-06
2025-06-08 22:55:27,901 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:00:32,226 - INFO - 
============================================================
2025-06-08 23:00:32,227 - INFO - 📊 VALIDATION 4/5 - Epoch 2, Step 3375
2025-06-08 23:00:32,227 - INFO - ============================================================
2025-06-08 23:00:32,227 - INFO -   • Average Loss: 0.6086
2025-06-08 23:00:32,227 - INFO -   • Sample Average: 0.6142 (10000 samples)
2025-06-08 23:00:45,059 - INFO - ✅ New best model saved in memory
2025-06-08 23:00:45,059 - INFO -   • Early Stop: 0/3
2025-06-08 23:00:45,059 - INFO -   • Best Loss: 0.6086 (epoch 1, step 3375)
2025-06-08 23:00:45,059 - INFO - ============================================================

2025-06-08 23:00:45,060 - INFO - 🏆 New best model! Saving...
2025-06-08 23:00:45,060 - INFO - 💾 Attempting to save model to: /root/llama3.2-3b-sft-training/best/model
2025-06-08 23:00:45,060 - INFO -    Trying standard safe save...
2025-06-08 23:00:45,064 - WARNING -    Standard safe save failed: cannot import name 'DTensor' from 'torch.distributed.tensor' (/usr/local/lib/python3.11/dist-packages/torch/distributed/tensor/__init__.py)
2025-06-08 23:00:45,064 - INFO -    Trying without safe serialization...
2025-06-08 23:00:45,084 - WARNING -    Non-safe save failed: name 'DTensor' is not defined
2025-06-08 23:00:45,084 - INFO -    Trying manual state dict save...
2025-06-08 23:00:52,594 - INFO - ✅ Manual save successful!
2025-06-08 23:01:19,230 - INFO - 💾 Checkpoint saved: /root/llama3.2-3b-sft-training/checkpoints/checkpoint-best.pt
2025-06-08 23:01:44,573 - INFO - 🚀 Step 3380 | Loss: 0.3984 | LR: 7.25e-06
2025-06-08 23:01:44,573 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:02:34,948 - INFO - 🚀 Step 3390 | Loss: 0.4126 | LR: 7.20e-06
2025-06-08 23:02:34,948 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:03:27,785 - INFO - 🚀 Step 3400 | Loss: 0.4326 | LR: 7.14e-06
2025-06-08 23:03:27,785 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:04:17,764 - INFO - 🚀 Step 3410 | Loss: 0.4097 | LR: 7.09e-06
2025-06-08 23:04:17,765 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:05:11,517 - INFO - 🚀 Step 3420 | Loss: 0.4353 | LR: 7.03e-06
2025-06-08 23:05:11,517 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:06:05,096 - INFO - 🚀 Step 3430 | Loss: 0.3965 | LR: 6.98e-06
2025-06-08 23:06:05,096 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:06:55,595 - INFO - 🚀 Step 3440 | Loss: 0.4301 | LR: 6.92e-06
2025-06-08 23:06:55,595 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:07:46,493 - INFO - 🚀 Step 3450 | Loss: 0.4203 | LR: 6.87e-06
2025-06-08 23:07:46,494 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:08:37,149 - INFO - 🚀 Step 3460 | Loss: 0.4114 | LR: 6.81e-06
2025-06-08 23:08:37,149 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:09:29,131 - INFO - 🚀 Step 3470 | Loss: 0.4381 | LR: 6.76e-06
2025-06-08 23:09:29,131 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:10:20,999 - INFO - 🚀 Step 3480 | Loss: 0.3930 | LR: 6.70e-06
2025-06-08 23:10:20,999 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:11:12,750 - INFO - 🚀 Step 3490 | Loss: 0.4305 | LR: 6.65e-06
2025-06-08 23:11:12,750 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:12:06,648 - INFO - 🚀 Step 3500 | Loss: 0.3834 | LR: 6.60e-06
2025-06-08 23:12:06,648 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:12:59,668 - INFO - 🚀 Step 3510 | Loss: 0.3683 | LR: 6.54e-06
2025-06-08 23:12:59,669 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:13:51,273 - INFO - 🚀 Step 3520 | Loss: 0.3989 | LR: 6.49e-06
2025-06-08 23:13:51,273 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:14:44,335 - INFO - 🚀 Step 3530 | Loss: 0.3856 | LR: 6.43e-06
2025-06-08 23:14:44,335 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:15:34,625 - INFO - 🚀 Step 3540 | Loss: 0.3885 | LR: 6.38e-06
2025-06-08 23:15:34,625 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:16:27,598 - INFO - 🚀 Step 3550 | Loss: 0.3999 | LR: 6.33e-06
2025-06-08 23:16:27,598 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:17:19,707 - INFO - 🚀 Step 3560 | Loss: 0.3807 | LR: 6.27e-06
2025-06-08 23:17:19,707 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:18:10,004 - INFO - 🚀 Step 3570 | Loss: 0.4203 | LR: 6.22e-06
2025-06-08 23:18:10,004 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:19:05,220 - INFO - 🚀 Step 3580 | Loss: 0.4162 | LR: 6.17e-06
2025-06-08 23:19:05,221 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:19:53,041 - INFO - 🚀 Step 3590 | Loss: 0.3968 | LR: 6.11e-06
2025-06-08 23:19:53,041 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:20:44,327 - INFO - 🚀 Step 3600 | Loss: 0.4049 | LR: 6.06e-06
2025-06-08 23:20:44,327 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:21:34,931 - INFO - 🚀 Step 3610 | Loss: 0.3945 | LR: 6.01e-06
2025-06-08 23:21:34,931 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:22:26,137 - INFO - 🚀 Step 3620 | Loss: 0.3837 | LR: 5.95e-06
2025-06-08 23:22:26,138 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:23:19,781 - INFO - 🚀 Step 3630 | Loss: 0.4002 | LR: 5.90e-06
2025-06-08 23:23:19,781 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:24:12,411 - INFO - 🚀 Step 3640 | Loss: 0.3708 | LR: 5.85e-06
2025-06-08 23:24:12,412 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:25:02,694 - INFO - 🚀 Step 3650 | Loss: 0.4173 | LR: 5.80e-06
2025-06-08 23:25:02,694 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:25:57,138 - INFO - 🚀 Step 3660 | Loss: 0.3826 | LR: 5.74e-06
2025-06-08 23:25:57,138 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:26:45,359 - INFO - 🚀 Step 3670 | Loss: 0.4120 | LR: 5.69e-06
2025-06-08 23:26:45,359 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:27:34,601 - INFO - 🚀 Step 3680 | Loss: 0.4358 | LR: 5.64e-06
2025-06-08 23:27:34,601 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:28:25,947 - INFO - 🚀 Step 3690 | Loss: 0.3889 | LR: 5.59e-06
2025-06-08 23:28:25,948 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:29:16,248 - INFO - 🚀 Step 3700 | Loss: 0.4202 | LR: 5.54e-06
2025-06-08 23:29:16,248 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:30:07,004 - INFO - 🚀 Step 3710 | Loss: 0.4010 | LR: 5.49e-06
2025-06-08 23:30:07,004 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:31:01,259 - INFO - 🚀 Step 3720 | Loss: 0.3991 | LR: 5.43e-06
2025-06-08 23:31:01,259 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:31:53,379 - INFO - 🚀 Step 3730 | Loss: 0.3839 | LR: 5.38e-06
2025-06-08 23:31:53,379 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:32:46,413 - INFO - 🚀 Step 3740 | Loss: 0.3944 | LR: 5.33e-06
2025-06-08 23:32:46,413 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:38:14,214 - INFO - 
============================================================
2025-06-08 23:38:14,215 - INFO - 📊 VALIDATION 5/5 - Epoch 2, Step 3750
2025-06-08 23:38:14,215 - INFO - ============================================================
2025-06-08 23:38:14,215 - INFO -   • Average Loss: 0.5943
2025-06-08 23:38:14,215 - INFO -   • Sample Average: 0.6012 (10000 samples)
2025-06-08 23:38:27,142 - INFO - ✅ New best model saved in memory
2025-06-08 23:38:27,142 - INFO -   • Early Stop: 0/3
2025-06-08 23:38:27,142 - INFO -   • Best Loss: 0.5943 (epoch 1, step 3750)
2025-06-08 23:38:27,142 - INFO - ============================================================

2025-06-08 23:38:27,143 - INFO - 🏆 New best model! Saving...
2025-06-08 23:38:27,143 - INFO - 💾 Attempting to save model to: /root/llama3.2-3b-sft-training/best/model
2025-06-08 23:38:27,143 - INFO -    Trying standard safe save...
2025-06-08 23:38:27,147 - WARNING -    Standard safe save failed: cannot import name 'DTensor' from 'torch.distributed.tensor' (/usr/local/lib/python3.11/dist-packages/torch/distributed/tensor/__init__.py)
2025-06-08 23:38:27,147 - INFO -    Trying without safe serialization...
2025-06-08 23:38:27,167 - WARNING -    Non-safe save failed: name 'DTensor' is not defined
2025-06-08 23:38:27,167 - INFO -    Trying manual state dict save...
2025-06-08 23:38:34,568 - INFO - ✅ Manual save successful!
2025-06-08 23:39:00,667 - INFO - 💾 Checkpoint saved: /root/llama3.2-3b-sft-training/checkpoints/checkpoint-best.pt
2025-06-08 23:39:00,668 - INFO - 🚀 Step 3750 | Loss: 0.3565 | LR: 5.28e-06
2025-06-08 23:39:00,668 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:39:00,669 - INFO - 💾 Saving epoch 2 checkpoint...
2025-06-08 23:39:23,650 - INFO - 💾 Checkpoint saved: /root/llama3.2-3b-sft-training/checkpoints/checkpoint-epoch-2.pt
2025-06-08 23:39:23,651 - INFO - 🎯 EPOCH 2 COMPLETED
2025-06-08 23:39:23,651 - INFO -    Time: 190.7 min
2025-06-08 23:39:23,651 - INFO -    Processed batches: 11250
2025-06-08 23:39:23,651 - INFO -    Global steps: 3750
2025-06-08 23:39:23,651 - INFO - 
🎯 EPOCH 3/3
2025-06-08 23:40:23,414 - INFO - 🚀 Step 3760 | Loss: 0.2903 | LR: 5.23e-06
2025-06-08 23:40:23,414 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:41:14,326 - INFO - 🚀 Step 3770 | Loss: 0.2653 | LR: 5.18e-06
2025-06-08 23:41:14,326 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:42:03,208 - INFO - 🚀 Step 3780 | Loss: 0.2589 | LR: 5.13e-06
2025-06-08 23:42:03,209 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:42:52,715 - INFO - 🚀 Step 3790 | Loss: 0.2836 | LR: 5.08e-06
2025-06-08 23:42:52,715 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:43:42,160 - INFO - 🚀 Step 3800 | Loss: 0.2893 | LR: 5.03e-06
2025-06-08 23:43:42,160 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:44:34,704 - INFO - 🚀 Step 3810 | Loss: 0.2625 | LR: 4.98e-06
2025-06-08 23:44:34,705 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:45:28,708 - INFO - 🚀 Step 3820 | Loss: 0.2716 | LR: 4.93e-06
2025-06-08 23:45:28,708 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:46:24,104 - INFO - 🚀 Step 3830 | Loss: 0.2778 | LR: 4.88e-06
2025-06-08 23:46:24,104 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:47:15,670 - INFO - 🚀 Step 3840 | Loss: 0.2728 | LR: 4.83e-06
2025-06-08 23:47:15,670 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:48:07,493 - INFO - 🚀 Step 3850 | Loss: 0.2596 | LR: 4.78e-06
2025-06-08 23:48:07,493 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:48:59,757 - INFO - 🚀 Step 3860 | Loss: 0.2709 | LR: 4.73e-06
2025-06-08 23:48:59,758 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:49:53,204 - INFO - 🚀 Step 3870 | Loss: 0.2999 | LR: 4.68e-06
2025-06-08 23:49:53,204 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:50:44,347 - INFO - 🚀 Step 3880 | Loss: 0.2788 | LR: 4.64e-06
2025-06-08 23:50:44,347 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:51:35,874 - INFO - 🚀 Step 3890 | Loss: 0.2696 | LR: 4.59e-06
2025-06-08 23:51:35,874 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:52:28,854 - INFO - 🚀 Step 3900 | Loss: 0.2644 | LR: 4.54e-06
2025-06-08 23:52:28,854 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:53:17,919 - INFO - 🚀 Step 3910 | Loss: 0.2506 | LR: 4.49e-06
2025-06-08 23:53:17,919 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:54:10,647 - INFO - 🚀 Step 3920 | Loss: 0.2813 | LR: 4.44e-06
2025-06-08 23:54:10,647 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:55:03,304 - INFO - 🚀 Step 3930 | Loss: 0.2759 | LR: 4.40e-06
2025-06-08 23:55:03,304 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:55:55,264 - INFO - 🚀 Step 3940 | Loss: 0.2718 | LR: 4.35e-06
2025-06-08 23:55:55,264 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:56:47,067 - INFO - 🚀 Step 3950 | Loss: 0.2597 | LR: 4.30e-06
2025-06-08 23:56:47,067 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:57:38,411 - INFO - 🚀 Step 3960 | Loss: 0.2746 | LR: 4.25e-06
2025-06-08 23:57:38,411 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:58:31,458 - INFO - 🚀 Step 3970 | Loss: 0.2557 | LR: 4.21e-06
2025-06-08 23:58:31,458 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-08 23:59:22,898 - INFO - 🚀 Step 3980 | Loss: 0.2900 | LR: 4.16e-06
2025-06-08 23:59:22,898 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:00:13,209 - INFO - 🚀 Step 3990 | Loss: 0.2446 | LR: 4.11e-06
2025-06-09 00:00:13,210 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:01:04,837 - INFO - 🚀 Step 4000 | Loss: 0.2797 | LR: 4.07e-06
2025-06-09 00:01:04,838 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:01:56,059 - INFO - 🚀 Step 4010 | Loss: 0.2738 | LR: 4.02e-06
2025-06-09 00:01:56,059 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:02:44,461 - INFO - 🚀 Step 4020 | Loss: 0.2590 | LR: 3.97e-06
2025-06-09 00:02:44,461 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:03:39,749 - INFO - 🚀 Step 4030 | Loss: 0.2926 | LR: 3.93e-06
2025-06-09 00:03:39,749 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:04:29,266 - INFO - 🚀 Step 4040 | Loss: 0.2725 | LR: 3.88e-06
2025-06-09 00:04:29,266 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:05:20,337 - INFO - 🚀 Step 4050 | Loss: 0.2565 | LR: 3.84e-06
2025-06-09 00:05:20,337 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:06:13,347 - INFO - 🚀 Step 4060 | Loss: 0.2643 | LR: 3.79e-06
2025-06-09 00:06:13,347 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:07:08,233 - INFO - 🚀 Step 4070 | Loss: 0.2630 | LR: 3.75e-06
2025-06-09 00:07:08,234 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:07:57,972 - INFO - 🚀 Step 4080 | Loss: 0.2701 | LR: 3.70e-06
2025-06-09 00:07:57,972 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:08:48,339 - INFO - 🚀 Step 4090 | Loss: 0.2496 | LR: 3.66e-06
2025-06-09 00:08:48,340 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:09:38,828 - INFO - 🚀 Step 4100 | Loss: 0.2710 | LR: 3.61e-06
2025-06-09 00:09:38,828 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:10:31,559 - INFO - 🚀 Step 4110 | Loss: 0.2312 | LR: 3.57e-06
2025-06-09 00:10:31,559 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:11:23,896 - INFO - 🚀 Step 4120 | Loss: 0.2578 | LR: 3.52e-06
2025-06-09 00:11:23,896 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:16:26,105 - INFO - 
============================================================
2025-06-09 00:16:26,106 - INFO - 📊 VALIDATION 1/5 - Epoch 3, Step 4125
2025-06-09 00:16:26,106 - INFO - ============================================================
2025-06-09 00:16:26,106 - INFO -   • Average Loss: 0.6096
2025-06-09 00:16:26,106 - INFO -   • Sample Average: 0.6176 (10000 samples)
2025-06-09 00:16:26,106 - INFO -   • Early Stop: 1/3
2025-06-09 00:16:26,106 - INFO -   • Best Loss: 0.5943 (epoch 1, step 3750)
2025-06-09 00:16:26,106 - INFO - ============================================================

2025-06-09 00:16:51,878 - INFO - 🚀 Step 4130 | Loss: 0.2759 | LR: 3.48e-06
2025-06-09 00:16:51,878 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:17:43,149 - INFO - 🚀 Step 4140 | Loss: 0.2745 | LR: 3.44e-06
2025-06-09 00:17:43,149 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:18:36,036 - INFO - 🚀 Step 4150 | Loss: 0.2666 | LR: 3.39e-06
2025-06-09 00:18:36,036 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:19:30,527 - INFO - 🚀 Step 4160 | Loss: 0.2779 | LR: 3.35e-06
2025-06-09 00:19:30,527 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:20:22,776 - INFO - 🚀 Step 4170 | Loss: 0.2617 | LR: 3.31e-06
2025-06-09 00:20:22,777 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:21:13,565 - INFO - 🚀 Step 4180 | Loss: 0.2637 | LR: 3.27e-06
2025-06-09 00:21:13,565 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:22:02,276 - INFO - 🚀 Step 4190 | Loss: 0.2898 | LR: 3.22e-06
2025-06-09 00:22:02,276 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:22:55,206 - INFO - 🚀 Step 4200 | Loss: 0.2611 | LR: 3.18e-06
2025-06-09 00:22:55,206 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:23:49,583 - INFO - 🚀 Step 4210 | Loss: 0.2753 | LR: 3.14e-06
2025-06-09 00:23:49,583 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:24:41,692 - INFO - 🚀 Step 4220 | Loss: 0.2594 | LR: 3.10e-06
2025-06-09 00:24:41,693 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:25:34,024 - INFO - 🚀 Step 4230 | Loss: 0.2590 | LR: 3.06e-06
2025-06-09 00:25:34,024 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:26:25,701 - INFO - 🚀 Step 4240 | Loss: 0.2629 | LR: 3.01e-06
2025-06-09 00:26:25,701 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:27:18,789 - INFO - 🚀 Step 4250 | Loss: 0.2365 | LR: 2.97e-06
2025-06-09 00:27:18,789 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:28:08,733 - INFO - 🚀 Step 4260 | Loss: 0.2814 | LR: 2.93e-06
2025-06-09 00:28:08,733 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:28:58,293 - INFO - 🚀 Step 4270 | Loss: 0.2558 | LR: 2.89e-06
2025-06-09 00:28:58,293 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:29:47,542 - INFO - 🚀 Step 4280 | Loss: 0.2697 | LR: 2.85e-06
2025-06-09 00:29:47,542 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:30:39,545 - INFO - 🚀 Step 4290 | Loss: 0.2628 | LR: 2.81e-06
2025-06-09 00:30:39,545 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:31:31,754 - INFO - 🚀 Step 4300 | Loss: 0.2627 | LR: 2.77e-06
2025-06-09 00:31:31,755 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:32:25,380 - INFO - 🚀 Step 4310 | Loss: 0.2938 | LR: 2.73e-06
2025-06-09 00:32:25,380 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:33:17,491 - INFO - 🚀 Step 4320 | Loss: 0.2708 | LR: 2.69e-06
2025-06-09 00:33:17,491 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:34:10,473 - INFO - 🚀 Step 4330 | Loss: 0.2486 | LR: 2.65e-06
2025-06-09 00:34:10,474 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:35:02,033 - INFO - 🚀 Step 4340 | Loss: 0.2337 | LR: 2.61e-06
2025-06-09 00:35:02,034 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:35:49,891 - INFO - 🚀 Step 4350 | Loss: 0.2636 | LR: 2.58e-06
2025-06-09 00:35:49,891 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:36:43,155 - INFO - 🚀 Step 4360 | Loss: 0.2917 | LR: 2.54e-06
2025-06-09 00:36:43,155 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:37:36,081 - INFO - 🚀 Step 4370 | Loss: 0.2767 | LR: 2.50e-06
2025-06-09 00:37:36,082 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:38:26,993 - INFO - 🚀 Step 4380 | Loss: 0.2676 | LR: 2.46e-06
2025-06-09 00:38:26,993 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:39:17,205 - INFO - 🚀 Step 4390 | Loss: 0.2553 | LR: 2.42e-06
2025-06-09 00:39:17,206 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:40:06,686 - INFO - 🚀 Step 4400 | Loss: 0.2653 | LR: 2.39e-06
2025-06-09 00:40:06,687 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:40:58,854 - INFO - 🚀 Step 4410 | Loss: 0.2414 | LR: 2.35e-06
2025-06-09 00:40:58,855 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:41:52,835 - INFO - 🚀 Step 4420 | Loss: 0.2762 | LR: 2.31e-06
2025-06-09 00:41:52,836 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:42:44,659 - INFO - 🚀 Step 4430 | Loss: 0.2579 | LR: 2.27e-06
2025-06-09 00:42:44,659 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:43:36,781 - INFO - 🚀 Step 4440 | Loss: 0.2439 | LR: 2.24e-06
2025-06-09 00:43:36,781 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:44:30,037 - INFO - 🚀 Step 4450 | Loss: 0.2629 | LR: 2.20e-06
2025-06-09 00:44:30,037 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:45:22,456 - INFO - 🚀 Step 4460 | Loss: 0.2472 | LR: 2.17e-06
2025-06-09 00:45:22,457 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:46:13,091 - INFO - 🚀 Step 4470 | Loss: 0.2837 | LR: 2.13e-06
2025-06-09 00:46:13,092 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:47:05,658 - INFO - 🚀 Step 4480 | Loss: 0.2612 | LR: 2.10e-06
2025-06-09 00:47:05,658 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:47:58,310 - INFO - 🚀 Step 4490 | Loss: 0.2653 | LR: 2.06e-06
2025-06-09 00:47:58,310 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:53:28,074 - INFO - 
============================================================
2025-06-09 00:53:28,075 - INFO - 📊 VALIDATION 2/5 - Epoch 3, Step 4500
2025-06-09 00:53:28,075 - INFO - ============================================================
2025-06-09 00:53:28,075 - INFO -   • Average Loss: 0.6027
2025-06-09 00:53:28,075 - INFO -   • Sample Average: 0.6112 (10000 samples)
2025-06-09 00:53:28,075 - INFO -   • Early Stop: 2/3
2025-06-09 00:53:28,075 - INFO -   • Best Loss: 0.5943 (epoch 1, step 3750)
2025-06-09 00:53:28,075 - INFO - ============================================================

2025-06-09 00:53:28,075 - INFO - 🚀 Step 4500 | Loss: 0.2725 | LR: 2.03e-06
2025-06-09 00:53:28,075 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:54:22,247 - INFO - 🚀 Step 4510 | Loss: 0.2709 | LR: 1.99e-06
2025-06-09 00:54:22,248 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:55:21,419 - INFO - 🚀 Step 4520 | Loss: 0.2556 | LR: 1.96e-06
2025-06-09 00:55:21,419 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:56:11,164 - INFO - 🚀 Step 4530 | Loss: 0.2448 | LR: 1.92e-06
2025-06-09 00:56:11,164 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:57:03,070 - INFO - 🚀 Step 4540 | Loss: 0.2455 | LR: 1.89e-06
2025-06-09 00:57:03,070 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:57:57,902 - INFO - 🚀 Step 4550 | Loss: 0.2542 | LR: 1.85e-06
2025-06-09 00:57:57,902 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:58:50,133 - INFO - 🚀 Step 4560 | Loss: 0.2574 | LR: 1.82e-06
2025-06-09 00:58:50,133 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 00:59:40,360 - INFO - 🚀 Step 4570 | Loss: 0.2521 | LR: 1.79e-06
2025-06-09 00:59:40,360 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:00:34,714 - INFO - 🚀 Step 4580 | Loss: 0.2624 | LR: 1.76e-06
2025-06-09 01:00:34,714 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:01:25,885 - INFO - 🚀 Step 4590 | Loss: 0.2524 | LR: 1.72e-06
2025-06-09 01:01:25,886 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:02:19,681 - INFO - 🚀 Step 4600 | Loss: 0.2596 | LR: 1.69e-06
2025-06-09 01:02:19,681 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:03:12,865 - INFO - 🚀 Step 4610 | Loss: 0.2611 | LR: 1.66e-06
2025-06-09 01:03:12,865 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:04:06,808 - INFO - 🚀 Step 4620 | Loss: 0.2772 | LR: 1.63e-06
2025-06-09 01:04:06,808 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:04:58,170 - INFO - 🚀 Step 4630 | Loss: 0.2696 | LR: 1.60e-06
2025-06-09 01:04:58,170 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:05:48,784 - INFO - 🚀 Step 4640 | Loss: 0.2642 | LR: 1.57e-06
2025-06-09 01:05:48,784 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:06:42,538 - INFO - 🚀 Step 4650 | Loss: 0.2844 | LR: 1.53e-06
2025-06-09 01:06:42,538 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:07:30,411 - INFO - 🚀 Step 4660 | Loss: 0.2564 | LR: 1.50e-06
2025-06-09 01:07:30,411 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:08:23,439 - INFO - 🚀 Step 4670 | Loss: 0.2693 | LR: 1.47e-06
2025-06-09 01:08:23,439 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:09:13,503 - INFO - 🚀 Step 4680 | Loss: 0.2444 | LR: 1.44e-06
2025-06-09 01:09:13,503 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:10:07,138 - INFO - 🚀 Step 4690 | Loss: 0.2471 | LR: 1.41e-06
2025-06-09 01:10:07,138 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:10:56,040 - INFO - 🚀 Step 4700 | Loss: 0.2707 | LR: 1.38e-06
2025-06-09 01:10:56,040 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:11:48,238 - INFO - 🚀 Step 4710 | Loss: 0.2423 | LR: 1.36e-06
2025-06-09 01:11:48,238 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:12:39,519 - INFO - 🚀 Step 4720 | Loss: 0.2456 | LR: 1.33e-06
2025-06-09 01:12:39,519 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:13:32,521 - INFO - 🚀 Step 4730 | Loss: 0.2823 | LR: 1.30e-06
2025-06-09 01:13:32,521 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:14:24,275 - INFO - 🚀 Step 4740 | Loss: 0.2592 | LR: 1.27e-06
2025-06-09 01:14:24,276 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:15:14,143 - INFO - 🚀 Step 4750 | Loss: 0.2747 | LR: 1.24e-06
2025-06-09 01:15:14,144 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:16:08,852 - INFO - 🚀 Step 4760 | Loss: 0.2605 | LR: 1.21e-06
2025-06-09 01:16:08,852 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:17:00,628 - INFO - 🚀 Step 4770 | Loss: 0.2659 | LR: 1.19e-06
2025-06-09 01:17:00,629 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:17:56,926 - INFO - 🚀 Step 4780 | Loss: 0.2977 | LR: 1.16e-06
2025-06-09 01:17:56,926 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:18:50,267 - INFO - 🚀 Step 4790 | Loss: 0.2543 | LR: 1.13e-06
2025-06-09 01:18:50,267 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:19:40,338 - INFO - 🚀 Step 4800 | Loss: 0.2566 | LR: 1.11e-06
2025-06-09 01:19:40,339 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:20:28,171 - INFO - 🚀 Step 4810 | Loss: 0.2570 | LR: 1.08e-06
2025-06-09 01:20:28,171 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:21:20,170 - INFO - 🚀 Step 4820 | Loss: 0.2465 | LR: 1.05e-06
2025-06-09 01:21:20,170 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:22:12,482 - INFO - 🚀 Step 4830 | Loss: 0.2775 | LR: 1.03e-06
2025-06-09 01:22:12,482 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:23:03,203 - INFO - 🚀 Step 4840 | Loss: 0.2767 | LR: 1.00e-06
2025-06-09 01:23:03,203 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:23:53,777 - INFO - 🚀 Step 4850 | Loss: 0.2367 | LR: 9.79e-07
2025-06-09 01:23:53,777 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:24:44,450 - INFO - 🚀 Step 4860 | Loss: 0.2636 | LR: 9.54e-07
2025-06-09 01:24:44,450 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:25:35,001 - INFO - 🚀 Step 4870 | Loss: 0.2573 | LR: 9.30e-07
2025-06-09 01:25:35,001 - INFO -    GPU: 35.9GB/79.3GB (45.3%)
2025-06-09 01:30:36,944 - INFO - 
============================================================
2025-06-09 01:30:36,944 - INFO - 📊 VALIDATION 3/5 - Epoch 3, Step 4875
2025-06-09 01:30:36,944 - INFO - ============================================================
2025-06-09 01:30:36,944 - INFO -   • Average Loss: 0.6008
2025-06-09 01:30:36,945 - INFO -   • Sample Average: 0.6096 (10000 samples)
2025-06-09 01:30:36,945 - INFO -   • Early Stop: 3/3
2025-06-09 01:30:36,945 - INFO -   • Best Loss: 0.5943 (epoch 1, step 3750)
2025-06-09 01:30:36,945 - INFO - ============================================================

2025-06-09 01:30:36,945 - INFO - 🛑 Early stopping triggered!
2025-06-09 01:30:36,945 - INFO -    Loss stopped improving for 3 evaluations
2025-06-09 01:30:36,945 - INFO - 💾 Attempting to save model to: /root/llama3.2-3b-sft-training/final/model
2025-06-09 01:30:36,945 - INFO -    Trying standard safe save...
2025-06-09 01:30:36,949 - WARNING -    Standard safe save failed: cannot import name 'DTensor' from 'torch.distributed.tensor' (/usr/local/lib/python3.11/dist-packages/torch/distributed/tensor/__init__.py)
2025-06-09 01:30:36,949 - INFO -    Trying without safe serialization...
2025-06-09 01:30:36,969 - WARNING -    Non-safe save failed: name 'DTensor' is not defined
2025-06-09 01:30:36,969 - INFO -    Trying manual state dict save...
2025-06-09 01:30:51,330 - INFO - ✅ Manual save successful!
2025-06-09 01:31:19,067 - INFO - 💾 Checkpoint saved: /root/llama3.2-3b-sft-training/checkpoints/checkpoint-final.pt
2025-06-09 01:31:19,068 - INFO - 📂 Loading best model from epoch 1, step 3750
2025-06-09 01:31:26,881 - INFO - 💾 Attempting to save model to: /root/llama3.2-3b-sft-training/best/model
2025-06-09 01:31:26,881 - INFO -    Trying standard safe save...
2025-06-09 01:31:26,885 - WARNING -    Standard safe save failed: cannot import name 'DTensor' from 'torch.distributed.tensor' (/usr/local/lib/python3.11/dist-packages/torch/distributed/tensor/__init__.py)
2025-06-09 01:31:26,885 - INFO -    Trying without safe serialization...
2025-06-09 01:31:26,944 - WARNING -    Non-safe save failed: name 'DTensor' is not defined
2025-06-09 01:31:26,944 - INFO -    Trying manual state dict save...
2025-06-09 01:31:36,802 - INFO - ✅ Manual save successful!
